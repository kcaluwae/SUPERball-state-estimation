{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib wx\n",
    "\n",
    "import numpy as np \n",
    "import rospy\n",
    "import rosbag\n",
    "from matplotlib import pylab as plt\n",
    "plt.ion()\n",
    "#scikits learn is needed to filter outliers\n",
    "from sklearn import linear_model, datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#specify all the topics to use (order matters, see topics_node_to_node)\n",
    "topics = ['/bbb2/0x2017_0xd','/bbb2/0x2017_0xe','/bbb2/0x2017_0xf','/bbb2/0x2017_0x10','/bbb2/0x2017_0x11','/bbb2/0x2017_0x12','/bbb2/0x2017_0x13','/bbb2/0x2017_0x14',\n",
    "          '/bbb2/0x2717_0xd','/bbb2/0x2717_0xe','/bbb2/0x2717_0xf','/bbb2/0x2717_0x10','/bbb2/0x2717_0x11','/bbb2/0x2717_0x12','/bbb2/0x2717_0x13','/bbb2/0x2717_0x14',\n",
    "          '/bbb4/0x2017_0xd','/bbb4/0x2017_0xe','/bbb4/0x2017_0xf','/bbb4/0x2017_0x10','/bbb4/0x2017_0x11','/bbb4/0x2017_0x12','/bbb4/0x2017_0x13','/bbb4/0x2017_0x14',\n",
    "          '/bbb4/0x2717_0xd','/bbb4/0x2717_0xe','/bbb4/0x2717_0xf','/bbb4/0x2717_0x10','/bbb4/0x2717_0x11','/bbb4/0x2717_0x12','/bbb4/0x2717_0x13','/bbb4/0x2717_0x14',\n",
    "          '/bbb6/0x2017_0xd','/bbb6/0x2017_0xe','/bbb6/0x2017_0xf','/bbb6/0x2017_0x10','/bbb6/0x2017_0x11','/bbb6/0x2017_0x12','/bbb6/0x2017_0x13','/bbb6/0x2017_0x14',\n",
    "          '/bbb6/0x2717_0xd','/bbb6/0x2717_0xe','/bbb6/0x2717_0xf','/bbb6/0x2717_0x10','/bbb6/0x2717_0x11','/bbb6/0x2717_0x12','/bbb6/0x2717_0x13','/bbb6/0x2717_0x14',\n",
    "          '/bbb8/0x2017_0xd','/bbb8/0x2017_0xe','/bbb8/0x2017_0xf','/bbb8/0x2017_0x10','/bbb8/0x2017_0x11','/bbb8/0x2017_0x12','/bbb8/0x2017_0x13','/bbb8/0x2017_0x14',\n",
    "          '/bbb8/0x2717_0xd','/bbb8/0x2717_0xe','/bbb8/0x2717_0xf','/bbb8/0x2717_0x10','/bbb8/0x2717_0x11','/bbb8/0x2717_0x12','/bbb8/0x2717_0x13','/bbb8/0x2717_0x14',\n",
    "          '/bbb10/0x2017_0xd','/bbb10/0x2017_0xe','/bbb10/0x2017_0xf','/bbb10/0x2017_0x10','/bbb10/0x2017_0x11','/bbb10/0x2017_0x12','/bbb10/0x2017_0x13','/bbb10/0x2017_0x14',\n",
    "          '/bbb10/0x2717_0xd','/bbb10/0x2717_0xe','/bbb10/0x2717_0xf','/bbb10/0x2717_0x10','/bbb10/0x2717_0x11','/bbb10/0x2717_0x12','/bbb10/0x2717_0x13','/bbb10/0x2717_0x14',\n",
    "          '/bbb12/0x2017_0xd','/bbb12/0x2017_0xe','/bbb12/0x2017_0xf','/bbb12/0x2017_0x10','/bbb12/0x2017_0x11','/bbb12/0x2017_0x12','/bbb12/0x2017_0x13','/bbb12/0x2017_0x14',\n",
    "          '/bbb12/0x2717_0xd','/bbb12/0x2717_0xe','/bbb12/0x2717_0xf','/bbb12/0x2717_0x10','/bbb12/0x2717_0x11','/bbb12/0x2717_0x12','/bbb12/0x2717_0x13','/bbb12/0x2717_0x14'\n",
    "         ]\n",
    "#the node tuples (from-to) corresponding to the above topics\n",
    "#Use actual numbers (i.e. node 1 is 1, not 0)\n",
    "topics_node_to_node = np.array([[2,13],\n",
    "                               [2,14],\n",
    "                               [2,15],\n",
    "                               [2,16],\n",
    "                                [2,17],\n",
    "                               [2,18],\n",
    "                               [2,19],\n",
    "                               [2,20],\n",
    "                               [1,13],\n",
    "                                [1,14],\n",
    "                                [1,15],\n",
    "                                [1,16],\n",
    "                                [1,17],\n",
    "                               [1,18],\n",
    "                               [1,19],\n",
    "                               [1,20],\n",
    "                                \n",
    "                                [4,13],\n",
    "                               [4,14],\n",
    "                               [4,15],\n",
    "                               [4,16],\n",
    "                                [4,17],\n",
    "                               [4,18],\n",
    "                               [4,19],\n",
    "                               [4,20],\n",
    "                               [3,13],\n",
    "                                [3,14],\n",
    "                                [3,15],\n",
    "                                [3,16],\n",
    "                                [3,17],\n",
    "                               [3,18],\n",
    "                               [3,19],\n",
    "                               [3,20],\n",
    "                                \n",
    "                                [6,13],\n",
    "                               [6,14],\n",
    "                               [6,15],\n",
    "                               [6,16],\n",
    "                                [6,17],\n",
    "                               [6,18],\n",
    "                               [6,19],\n",
    "                               [6,20],\n",
    "                               [5,13],\n",
    "                                [5,14],\n",
    "                                [5,15],\n",
    "                                [5,16],\n",
    "                                [5,17],\n",
    "                               [5,18],\n",
    "                               [5,19],\n",
    "                               [5,20],\n",
    "                                \n",
    "                                [8,13],\n",
    "                               [8,14],\n",
    "                               [8,15],\n",
    "                               [8,16],\n",
    "                                [8,17],\n",
    "                               [8,18],\n",
    "                               [8,19],\n",
    "                               [8,20],\n",
    "                               [7,13],\n",
    "                                [7,14],\n",
    "                                [7,15],\n",
    "                                [7,16],\n",
    "                                [7,17],\n",
    "                               [7,18],\n",
    "                               [7,19],\n",
    "                               [7,20],\n",
    "                                \n",
    "                                [10,13],\n",
    "                               [10,14],\n",
    "                               [10,15],\n",
    "                               [10,16],\n",
    "                                [10,17],\n",
    "                               [10,18],\n",
    "                               [10,19],\n",
    "                               [10,20],\n",
    "                               [9,13],\n",
    "                                [9,14],\n",
    "                                [9,15],\n",
    "                                [9,16],\n",
    "                                [9,17],\n",
    "                               [9,18],\n",
    "                               [9,19],\n",
    "                               [9,20],\n",
    "                                \n",
    "                                [12,13],\n",
    "                               [12,14],\n",
    "                               [12,15],\n",
    "                               [12,16],\n",
    "                                [12,17],\n",
    "                               [12,18],\n",
    "                               [12,19],\n",
    "                               [12,20],\n",
    "                               [11,13],\n",
    "                                [11,14],\n",
    "                                [11,15],\n",
    "                                [11,16],\n",
    "                                [11,17],\n",
    "                               [11,18],\n",
    "                               [11,19],\n",
    "                               [11,20],\n",
    "                               ],dtype=int) #corresponds to topics above\n",
    "\n",
    "\n",
    "bag_names = []\n",
    "measured_distances = []\n",
    "node_to_sensor = []\n",
    "\n",
    "#add bag files to process\n",
    "bag_names.append(\"outdoor_ranging_8_anchors_round_2_2015-10-15-16-24-00.bag\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outdoor_ranging_8_anchors_round_2_2015-10-15-16-24-00.bag\n"
     ]
    }
   ],
   "source": [
    "#process all bag files by filtering out bad data (this takes a while).\n",
    "#plot raw data\n",
    "#plt.close('all')\n",
    "bag_means = []\n",
    "bag_std = []\n",
    "bag_means_raw = []\n",
    "bag_stds_raw = []\n",
    "bag_means_nodes = []\n",
    "bag_std_nodes = []\n",
    "data_clean = []\n",
    "for n_i,n in enumerate(bag_names):\n",
    "    print n\n",
    "    bag = rosbag.Bag(n)\n",
    "    data = {}\n",
    "    topics_mean = np.zeros(len(topics))\n",
    "    topics_std = np.zeros(len(topics))\n",
    "    plt.figure()\n",
    "    d_supahclean = []\n",
    "    for i,t in enumerate(topics):\n",
    "        plt.subplot(12,1,i/8+1)\n",
    "        data = []\n",
    "        for m in bag.read_messages(topics=[t]):\n",
    "            data.append((m[1].header.stamp.to_sec(),m[1].data))\n",
    "        d = np.array(data)\n",
    "        try:\n",
    "            d_clean = d[np.where((d[:,1]>3.5)&(d[:,1]<25))[0]] #remove bad measurements\n",
    "        except:\n",
    "            d_supahclean.append(np.zeros((1,2)))\n",
    "            print \"err\"\n",
    "            continue\n",
    "        if(d_clean.shape[0]>10):\n",
    "            #we use RANSAC to robustly estimate the mean and variance and filter out outliers\n",
    "            model_ransac = linear_model.RANSACRegressor(linear_model.LinearRegression())\n",
    "            model_ransac.fit(np.arange(d_clean.shape[0]).reshape((-1,1)), d_clean)\n",
    "            inlier_mask = model_ransac.inlier_mask_\n",
    "            outlier_mask = np.logical_not(inlier_mask)\n",
    "            m = d_clean[inlier_mask,1].mean()\n",
    "            std = d_clean[inlier_mask,1].std()\n",
    "            d_outlier = d_clean[np.where((np.abs(d_clean[:,1]-m)<3*std))[0],:] #keep points within 3 std dev of the mean (less restrictive than RANSAC)\n",
    "            topics_mean[i] = d_outlier[:,1].mean()\n",
    "            topics_std[i] = d_outlier[:,1].std()\n",
    "            #plt.plot(d_clean)\n",
    "            #plt.plot(d_clean[inlier_mask])\n",
    "            #plt.plot(d_outlier[:,0]-d_outlier[0,0],d_outlier[:,1],'.')\n",
    "            #plt.plot(d_outlier[:,0]-d_outlier[0,0],d_outlier[:,1])\n",
    "            \n",
    "            d = d_outlier.copy()\n",
    "            good_data = []\n",
    "            good_data.append(d[0])\n",
    "            v_d = np.zeros(d.shape)\n",
    "            for i in xrange(1,d.shape[0]):\n",
    "                t_1 = good_data[-1][0]\n",
    "                t = d[i,0]\n",
    "                p_1 = good_data[-1][1]\n",
    "                p = d[i,1]\n",
    "                v = np.abs((p-p_1)/(t-t_1))\n",
    "                v_d[i]=v\n",
    "                if(v<2.5):\n",
    "                    good_data.append(d[i])\n",
    "            good_data=np.array(good_data)\n",
    "            #plt.plot(d_outlier[:,0]-d_outlier[0,0],d_outlier[:,1],'+')\n",
    "            plt.plot(good_data[:,0]-d_outlier[0,0],good_data[:,1],'.')\n",
    "            plt.plot(good_data[:,0]-d_outlier[0,0],good_data[:,1],'-')\n",
    "            d_supahclean.append(good_data.copy())\n",
    "        else:\n",
    "            topics_mean[i] = 0\n",
    "            topics_std[i] = 0\n",
    "            d_supahclean.append(np.zeros((1,2)))\n",
    "    data_clean.append(d_supahclean) #contains the valid data for each topic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/numpy/core/_methods.py:59: RuntimeWarning: Mean of empty slice.\n",
      "  warnings.warn(\"Mean of empty slice.\", RuntimeWarning)\n",
      "/usr/local/lib/python2.7/dist-packages/numpy/core/_methods.py:71: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "#convert to fixed rate by taking the mean per time step\n",
    "meas = []\n",
    "for n_i,n in enumerate(bag_names):\n",
    "    data = data_clean[n_i]\n",
    "    t0 = np.max([d[0,0] for d in data[:8]])\n",
    "    tend = np.min([d[-1,0] for d in data[:8]])\n",
    "    timesteps = np.arange(t0,tend,0.25)\n",
    "    measurements = np.zeros((timesteps.shape[0],len(topics)))\n",
    "    \n",
    "    for t_i, t in enumerate(timesteps):\n",
    "        for j in xrange(len(topics)):\n",
    "            d = data[j]\n",
    "            #get all matching data\n",
    "            idx = np.where((d[:,0]>=t) & (d[:,0]<t+0.25))[0]\n",
    "            if(idx.shape>0):\n",
    "                measurements[t_i,j] = np.median(d[idx,1])\n",
    "            else:\n",
    "                measurements[t_i,j] = 0 \n",
    "    meas.append(measurements)#[np.where(np.sum((measurements[:,:8]>1) & (measurements[:,:8]<30),1)>2)]) #how many valid measurements do we need?\n",
    "    #TODO: for multiple nodes, make sure each one has at least 4  ranging measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/IPython/kernel/__main__.py:7: RuntimeWarning: invalid value encountered in greater\n",
      "/usr/local/lib/python2.7/dist-packages/IPython/kernel/__main__.py:7: RuntimeWarning: invalid value encountered in less\n"
     ]
    }
   ],
   "source": [
    "#Plot data samples with at least 4 measurements per floating node \n",
    "p1 = plt.figure()\n",
    "p2 = plt.figure()\n",
    "for i in xrange(12):\n",
    "    plt.figure(p1.number)\n",
    "    plt.subplot(3,4,i+1)\n",
    "    m = [np.where(np.sum((meas[0][:,i*8:(i+1)*8]>1) & (meas[0][:,i*8:(i+1)*8]<30),1)>3)]\n",
    "    plt.plot(meas[0][:,i*8:(i+1)*8])\n",
    "    plt.figure(p2.number)\n",
    "    for j in xrange(8):\n",
    "        plt.subplot(2,4,j+1)\n",
    "        plt.plot(meas[0][:,i*8:(i+1)*8][:,j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#This code is used to generate all the constraints.\n",
    "\n",
    "#Define the cost function and its derivatives (x,y) are coordinates, m are measurements and o are measurement offsets\n",
    "def cost_function(x,y,m,o):\n",
    "    '''\n",
    "        Assumes x and y are Nx3, m and o are 1d vectors\n",
    "    '''\n",
    "    dist_xy = np.sqrt(np.sum((x-y)**2,1)) #1d vector\n",
    "    cost_per_element = (dist_xy-(m-o))**2\n",
    "    total_cost = cost_per_element.mean()\n",
    "    return total_cost\n",
    "\n",
    "def derivative_cost_function(x,y,m,o):\n",
    "    '''\n",
    "        Derivatives of the cost function wrt x,y and o\n",
    "    '''\n",
    "    dist_xy = np.sqrt(np.sum((x-y)**2,1)) #1d vector\n",
    "    factor = 2*(dist_xy-(m-o))/dist_xy/m.shape[0]\n",
    "    #derivative with respect to x\n",
    "    deriv_x = factor.reshape((-1,1))*(x-y)\n",
    "    #derivative with respect to y\n",
    "    deriv_y = -deriv_x\n",
    "    #derivative with respect to o\n",
    "    deriv_o = factor*dist_xy\n",
    "    return deriv_x, deriv_y, deriv_o\n",
    "\n",
    "\n",
    "def create_data(fixed_nodes,floating_nodes,measurement_pairs,measurements):\n",
    "    '''\n",
    "        fixed nodes: indices in measurement_pairs corresponding to fixed nodes\n",
    "        floating nodes: indices in measurement_paris correspond to floating nodes\n",
    "        measurements pairs: each column in measurements corresponds to a distance between two nodes as specified by the rows in this matrix\n",
    "        measurements: num_measurements x num pairs observed distances\n",
    "        \n",
    "    '''\n",
    "    num_fixed = fixed_nodes.shape[0]\n",
    "    num_floating = floating_nodes.shape[0]\n",
    "    num_measurements = measurements.shape[0]\n",
    "    measurement_pairs = measurement_pairs.copy()\n",
    "    \n",
    "    floating_to_fixed = {} #contains an array of indices in measurement_pairs for each node\n",
    "    floating_to_floating = {} #similar\n",
    "    bars = {1:(2,1.37),3:(4,1.37),5:(6,1.37),7:(8,1.37),9:(10,1.37),11:(12,1.37)} #nodes with bar connections: FROM: (TO,LENGTH)\n",
    "    \n",
    "    #for each floating node, find the measurement pairs to fixed nodes\n",
    "    for node_idx, node in enumerate(floating_nodes):\n",
    "        #get measurement columns corresponding to this node (to/from)        \n",
    "        node_dist_idx = np.where((measurement_pairs[:,0] == node) | (measurement_pairs[:,1] == node))[0]\n",
    "        #create new array\n",
    "        floating_to_fixed[node] = []        \n",
    "        for i in node_dist_idx:\n",
    "            if(measurement_pairs[i,0] in fixed_nodes or measurement_pairs[i,1] in fixed_nodes):\n",
    "                #found one\n",
    "                floating_to_fixed[node].append(i)\n",
    "                \n",
    "    #for each floating node, find the measurement pairs to other floating nodes\n",
    "    for node_idx, node in enumerate(floating_nodes):\n",
    "        #get measurement columns corresponding to this node (to/from)        \n",
    "        node_dist_idx = np.where((measurement_pairs[:,0] == node) | (measurement_pairs[:,1] == node))[0]\n",
    "        #create new array\n",
    "        floating_to_floating[node] = []        \n",
    "        for pair_idx in node_dist_idx:\n",
    "            #to prevent doubles, we only add pairs originating FROM this node TO another floating node\n",
    "            if((measurement_pairs[pair_idx,0] == node) and measurement_pairs[pair_idx,1] in floating_nodes):\n",
    "                #found one\n",
    "                floating_to_floating[node].append(pair_idx)\n",
    "    \n",
    "    \n",
    "    #Find all the floating node positions with enough measurements for ranging\n",
    "    #enough means more than 3 valid measurements to fixed nodes\n",
    "    floating_valid_points = np.zeros((num_measurements,num_floating),dtype=bool)\n",
    "    measurements_valid = (measurements>1) & (measurements<20) #this matrix contains a one for each valid measurements\n",
    "    #a one in the above matrix indicates that there are enough valid measurements between a floating node and fixed nodes available for the \n",
    "    #columns correspond to indices in floating_nodes\n",
    "    for node_idx, node in enumerate(floating_nodes):\n",
    "        for timestep_idx in xrange(num_measurements):\n",
    "            #get all measurements to fixed nodes from this node\n",
    "            to_fixed = floating_to_fixed[node]\n",
    "            valid_cnt = 0\n",
    "            for pair_idx in to_fixed:\n",
    "                if(measurements_valid[timestep_idx,pair_idx]):\n",
    "                    #this is a valid measurement, use it\n",
    "                    valid_cnt += 1\n",
    "            if(valid_cnt >= 4):\n",
    "                #we can estimate this location at this timestep\n",
    "                floating_valid_points[timestep_idx,node_idx] = True\n",
    "\n",
    "    #we now know all the valid coordinates to estimate, so we are ready to create constraints\n",
    "        \n",
    "    #print floating_to_fixed\n",
    "    #print floating_to_floating\n",
    "        \n",
    "    #create distance constraints between floating nodes and fixed nodes for all valid time steps with valid measurements per floating node\n",
    "    constraints = []\n",
    "    \n",
    "    for timestep_idx in xrange(num_measurements): #iterate over time steps\n",
    "        for node_idx, node in enumerate(floating_nodes): #iterate over nodes\n",
    "            if(floating_valid_points[timestep_idx,node_idx]):\n",
    "                #This is a valid measurement timestep, \n",
    "                #add a constraint for each valid measurement to the respective anchor.\n",
    "                to_fixed = floating_to_fixed[node]\n",
    "                for pair_idx in to_fixed:\n",
    "                    if(measurements_valid[timestep_idx,pair_idx]):\n",
    "                        constraints.append((\"float_to_fixed\",\n",
    "                                            measurement_pairs[pair_idx],\n",
    "                                            measurements[timestep_idx,pair_idx],\n",
    "                                            timestep_idx))\n",
    "                #add constraints to other valid floating nodes\n",
    "                to_floating = floating_to_floating[node]\n",
    "                for pair_idx in to_floating:\n",
    "                    if(measurements_valid[timestep_idx,pair_idx]):\n",
    "                        pair = measurement_pairs[pair_idx]\n",
    "                        from_ = np.where(floating_nodes == pair[0])[0][0]\n",
    "                        to_ = np.where(floating_nodes == pair[1])[0][0]\n",
    "                        if(floating_valid_points[timestep_idx,from_] and floating_valid_points[timestep_idx,to_]): #make sure destination node is valid at the current timestep\n",
    "                            \n",
    "                            constraints.append((\"float_to_float\",\n",
    "                                            measurement_pairs[pair_idx],\n",
    "                                            measurements[timestep_idx,pair_idx],\n",
    "                                            timestep_idx))\n",
    "                        \n",
    "                #add bar constraints\n",
    "                if(node in bars):\n",
    "                    b = bars[node]\n",
    "                    bar_node = b[0]\n",
    "                    #check whether destination node location is valid at this timestep\n",
    "                    if(floating_valid_points[timestep_idx,np.where(floating_nodes == bar_node)[0][0]]):\n",
    "                        #ok, we can add the constraint\n",
    "                        constraints.append((\"bar\",\n",
    "                                            [node,bar_node],\n",
    "                                            b[1],\n",
    "                                           timestep_idx))\n",
    "    \n",
    "    #create variables (this is the fun part)\n",
    "    variable_to_node = [] #indicates which variable corresponds to which node\n",
    "    for n in fixed_nodes:\n",
    "        variable_to_node.append(n) #first indices are fixed nodes\n",
    "    for timestep_idx in xrange(num_measurements): #iterate over time steps\n",
    "        for node_idx, node in enumerate(floating_nodes): #iterate over nodes\n",
    "            if(floating_valid_points[timestep_idx,node_idx]):\n",
    "                variable_to_node.append((node,timestep_idx)) #we store the floating nodes as node, timestep tuples\n",
    "    variable_to_node_map = {}\n",
    "    for v_idx,v in enumerate(variable_to_node):\n",
    "        variable_to_node_map[v] = v_idx\n",
    "    \n",
    "    #print len(variable_to_node)\n",
    "    \n",
    "    offset_variable_to_pair = [] #offset variables: pairs of nodes == tricky\n",
    "    for c in constraints:\n",
    "        #find out if we already have an offset variable for this constraint pair\n",
    "        if(not c[0]==\"bar\"): #bar constraints don't have offsets\n",
    "            pair = tuple(np.sort(c[1]))\n",
    "            if(not pair in offset_variable_to_pair):\n",
    "                offset_variable_to_pair.append(pair)\n",
    "    \n",
    "    num_offsets = len(offset_variable_to_pair)\n",
    "    num_variables = len(variable_to_node)\n",
    "    num_constraints = len(constraints)\n",
    "    \n",
    "    #print len(offset_variable_to_pair)\n",
    "    #TODO: constraints\n",
    "    #print len(constraints)\n",
    "    \n",
    "    #Generate the measurement vector, variable to constraint matrices and offset to constraint matrices\n",
    "    measurement_vector = np.zeros(num_constraints)\n",
    "    variables_to_CSTR_X = np.zeros((num_constraints,num_variables))\n",
    "    variables_to_CSTR_Y = np.zeros(variables_to_CSTR_X.shape)\n",
    "    offsets_to_CSTR = np.zeros((num_constraints,num_offsets))\n",
    "    #print floating_valid_points\n",
    "    for c_idx,c in enumerate(constraints):\n",
    "        measurement_vector[c_idx] = c[2]\n",
    "        #find the correct offset variable\n",
    "        if(c[0]==\"bar\"):\n",
    "            #bar constraints don't have offsets\n",
    "            offsets_to_CSTR[c_idx,:] = 0 \n",
    "        else:\n",
    "            pair = tuple(np.sort(c[1]))\n",
    "            offset_idx = offset_variable_to_pair.index(pair)\n",
    "            offsets_to_CSTR[c_idx,offset_idx] = 1 \n",
    "        #find the correct nodal coordinate variables\n",
    "        if(c[0]==\"bar\" or c[0]==\"float_to_float\"):\n",
    "            #print c\n",
    "            from_ = tuple((c[1][0],c[3])) #node,timestep\n",
    "            to_ = tuple((c[1][1],c[3]))\n",
    "            from_idx = variable_to_node_map[from_]\n",
    "            to_idx = variable_to_node_map[to_]\n",
    "            variables_to_CSTR_X[c_idx,from_idx] = 1\n",
    "            variables_to_CSTR_Y[c_idx,to_idx] = 1\n",
    "        else:\n",
    "            #float to fixed\n",
    "            if(c[1][0] in fixed_nodes):\n",
    "                from_ = c[1][0]\n",
    "                to_ = tuple((c[1][1],c[3]))\n",
    "            else:\n",
    "                from_ = tuple((c[1][0],c[3]))\n",
    "                to_ = c[1][1]\n",
    "\n",
    "            from_idx = variable_to_node_map[from_]\n",
    "            to_idx = variable_to_node_map[to_]\n",
    "            variables_to_CSTR_X[c_idx,from_idx] = 1\n",
    "            variables_to_CSTR_Y[c_idx,to_idx] = 1\n",
    "        #variables_to_CSTR_X[c_idx,variable_to_node.index(c[1][0])] = 1\n",
    "        #variables_to_CSTR_Y[c_idx,variable_to_node.index(c[1][1])] = 1\n",
    "        \n",
    "        \n",
    "    def deriv_func(N,o):\n",
    "        X = variables_to_CSTR_X.dot(N)\n",
    "        Y = variables_to_CSTR_Y.dot(N)\n",
    "        O = offsets_to_CSTR.dot(o.reshape((num_offsets,1))) \n",
    "        #print X.shape\n",
    "        #print Y.shape\n",
    "        #print O.shape\n",
    "        #print m.shape\n",
    "        dX,dY,dO = derivative_cost_function(X,Y,measurement_vector.ravel(),O.ravel())\n",
    "        dN = variables_to_CSTR_X.T.dot(dX) +  variables_to_CSTR_Y.T.dot(dY)\n",
    "        dN[0,:] = 0\n",
    "        dN[1,1:] = 0\n",
    "        dN[2,2] = 0\n",
    "        do = offsets_to_CSTR.T.dot(dO.reshape((-1,1))).ravel()\n",
    "        return dN,do\n",
    "    \n",
    "    def cost_func(N,o):\n",
    "        X = variables_to_CSTR_X.dot(N)\n",
    "        Y = variables_to_CSTR_Y.dot(N)\n",
    "        O = offsets_to_CSTR.dot(o.reshape((num_offsets,1))) \n",
    "        return cost_function(X,Y,measurement_vector.ravel(),O.ravel())\n",
    "    \n",
    "    #print offsets_to_CSTR\n",
    "    #print variables_to_CSTR_X\n",
    "    #create m vector\n",
    "    return deriv_func,cost_func, num_variables, num_offsets, variable_to_node, variable_to_node_map, offset_variable_to_pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#in case you want to save/load data\n",
    "#import scipy.io as sio\n",
    "#sio.savemat(\"data_outdoors_preprocessed.mat\",\n",
    "#            {'fixed_nodes':fixed_nodes,'floating_nodes':floating_nodes,'dist_pairs':dist_pairs,'m':m})\n",
    "#d = sio.loadmat('data_outdoors_preprocessed.mat')\n",
    "#fixed_nodes = d['fixed_nodes']\n",
    "#floating_nodes = d['floating_nodes']\n",
    "#dist_pairs = d['dist_pairs']\n",
    "#meas = d['meas']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.214538493577\n",
      "0.203845893025\n",
      "0.200950066441\n",
      "0.163409803814\n",
      "0.248281463984\n",
      "0.202402865018\n",
      "0.166095130279\n",
      "0.161378311887\n",
      "0.254283987108\n",
      "0.189255301955\n",
      "0.267274160651\n",
      "0.218182194274\n",
      "0.0833889857914\n",
      "0.227151070085\n",
      "0.196155471743\n",
      "0.272930021357\n",
      "0.182951805017\n",
      "0.264037549314\n",
      "0.237393023686\n",
      "0.183803613417\n",
      "0.17112068895\n",
      "0.254473038117\n",
      "0.285368673382\n",
      "0.328379212891\n",
      "0.0657679199866\n",
      "0.194747174228\n",
      "0.216636156032\n",
      "0.202550515725\n",
      "0.202275764077\n",
      "0.243026067662\n",
      "0.131094890078\n",
      "0.244348763887\n",
      "0.302228172415\n",
      "0.192607048038\n",
      "0.103762872544\n",
      "0.277637902502\n",
      "0.198257947901\n",
      "0.242733720411\n",
      "0.270135304423\n",
      "0.206688096044\n",
      "0.161080398161\n",
      "0.246464238035\n",
      "0.192326972335\n",
      "0.233455083151\n",
      "0.277352891701\n",
      "0.282359923716\n",
      "0.180903569784\n",
      "0.165084480046\n",
      "0.172489941354\n",
      "0.0789478117531\n",
      "0.221212012911\n",
      "0.297485099405\n",
      "0.173030145745\n",
      "0.187650559582\n",
      "0.343949772721\n",
      "0.196975432062\n",
      "0.21627599129\n",
      "0.158639099652\n",
      "0.192690395166\n",
      "0.0994792567568\n",
      "0.142166572121\n",
      "0.161332888249\n",
      "0.105138970074\n",
      "0.129398425912\n",
      "0.243782004672\n",
      "0.260536929404\n",
      "0.140941223348\n",
      "0.275168025761\n",
      "0.318604733639\n",
      "0.134392311046\n",
      "0.163679225079\n",
      "0.119592722662\n",
      "0.247631479475\n",
      "0.159774236957\n",
      "0.224221107737\n",
      "0.306705937237\n",
      "0.191141483844\n",
      "0.135101476874\n",
      "0.167864909773\n",
      "0.211107697383\n",
      "0.212092609278\n",
      "0.240981533512\n",
      "0.169281804598\n",
      "0.271287757679\n",
      "0.346233182795\n",
      "0.311298695082\n",
      "0.11485329482\n",
      "0.195967836444\n",
      "0.208760998392\n",
      "0.200658191959\n",
      "0.224357056308\n",
      "0.244611108902\n",
      "0.202610911142\n",
      "0.253655059955\n",
      "0.186499467584\n",
      "0.247330737079\n",
      "0.252279788928\n",
      "0.193482470269\n",
      "0.195096702835\n",
      "0.162176782269\n",
      "0.209412777858\n",
      "0.232796501108\n",
      "0.229538193119\n",
      "0.228663336228\n",
      "0.334885108785\n",
      "0.245998410253\n",
      "0.0809617482537\n",
      "0.178965909182\n",
      "0.266237294083\n",
      "0.254629401798\n",
      "0.282797497073\n",
      "0.247427027563\n",
      "0.200704722032\n",
      "0.144096414379\n",
      "0.261321609216\n",
      "0.312191518752\n",
      "0.1006207407\n",
      "0.185969217783"
     ]
    }
   ],
   "source": [
    "#This is the \"main loop\"\n",
    "cf = 10\n",
    "cf_min = cf\n",
    "results_and_costs = []\n",
    "while cf>0.00001:\n",
    "    fixed_nodes = np.array([16,15,13,14,17,18,19,20],dtype=int) #list the anchors\n",
    "    floating_nodes = np.array([3,4,5,6,7,8,9,10,],dtype=int)#,2],dtype=int) #list the nodes on the robot\n",
    "    #dist_pairs = np.array([[2,13],[2,14],[2,15],[2,16],\n",
    "    #                       [1,13],[1,14],[1,15],[1,16],\n",
    "    #                       [4,13],[1,14],[1,15],[1,16],\n",
    "    #                       [6,13],[1,14],[1,15],[1,16],\n",
    "    #                       [8,13],[1,14],[1,15],[1,16],\n",
    "    #                       [,13],[1,14],[1,15],[1,16],\n",
    "    #                       [1,13],[1,14],[1,15],[1,16]\n",
    "    #                      ],dtype=int)\n",
    "                           #np.array([[1,10],[2,10],[4,10],[7,10],[8,10],[12,10],[13,10],[16,10]],dtype=int)\n",
    "    dist_pairs = topics_node_to_node #list the nodal pairs (columns in measurements)\n",
    "\n",
    "    a = np.arange(meas[0].shape[0]) #which data to use (I like to shuffle and then subsample data)\n",
    "    np.random.shuffle(a)\n",
    "    m = meas[0][a[:400],:]#[:,(0,1,2,3,4,5,6,8)]\n",
    "    \n",
    "    #create constraints\n",
    "    df,cf,DOF,num_offsets,variable_to_node,variable_to_node_map, offset_variable_to_pair  = create_data(fixed_nodes,floating_nodes,dist_pairs,m)\n",
    "\n",
    "    #Initialize optimization variables\n",
    "    N,o = np.random.randn(DOF,3)*3,np.zeros(num_offsets)+3.8\n",
    "    N[0] = 0\n",
    "    N[1,1:] = 0\n",
    "    N[2,2] = 0     \n",
    "    #B=np.array([[ 0.,          0.,          0.        ],\n",
    "    #                 [ -3.38,  0.,          0.        ],\n",
    "    #                 [ -0.7039,  -2.189,  0.        ]])\n",
    "    #Set this if you know the first three anchor locations\n",
    "    B = np.array([[0,0,0],\n",
    "                 [9.97,0,0],\n",
    "                 [3.15,11.16,0]])\n",
    "    #N[:3] = B\n",
    "\n",
    "    dN,do = df(N,o)\n",
    "    #print cf(N,o)\n",
    "\n",
    "    import scipy.optimize as so\n",
    "    Nf = N.ravel()\n",
    "    X_initial = np.hstack((Nf,o))\n",
    "    def cost_fun(x):\n",
    "        Nt = x[:-o.shape[0]].reshape((DOF,3))\n",
    "        #Nt[:3] = B #uncomment if the first 3 anchor locations are known\n",
    "        #Regularization of the offsets\n",
    "        reg = 0.001*np.sum((x[-o.shape[0]:]-3.8)**2)#+0.5*(x[11]-2.5)**2#+0.05*(x[10]-2.)**2+0.05*(x[9]-2.)**2\n",
    "        return cf(Nt ,x[-o.shape[0]:])+reg\n",
    "    def cost_grad(x):\n",
    "        dN,do = df(x[:-o.shape[0]].reshape((DOF,3)),x[-o.shape[0]:])\n",
    "        #dN[:3] = 0 #uncomment if the first 3 anchor locations are known\n",
    "        #do[:] = 0\n",
    "        #Regularization of the offsets\n",
    "        do += 0.001*2*(x[-o.shape[0]:]-3.8)\n",
    "        dN = dN.ravel()\n",
    "        return np.hstack((dN,do))\n",
    "\n",
    "\n",
    "    resall = []\n",
    "    def progress(x):\n",
    "        resall.append(x)\n",
    "\n",
    "    #Truncated Newton is fast, but BFGS is also an OK choice\n",
    "    res = so.minimize(cost_fun,X_initial,jac=cost_grad,method='TNC')#,options={'xtol':1e-15,'disp':True})\n",
    "    #res = so.fm\n",
    "    #print df(res[:-o.shape[0]].reshape((DOF,3)),res[-o.shape[0]:])[1]\n",
    "    cf = res.fun#cost_fun(res.x)\n",
    "    results_and_costs.append((res.copy(),cf,variable_to_node_map,offset_variable_to_pair,a.copy()))\n",
    "    if(cf<cf_min):\n",
    "        res_min = res.copy()\n",
    "        DOF_min = DOF\n",
    "        variable_to_node_map_min =  variable_to_node_map\n",
    "        offset_variable_to_pair_min = offset_variable_to_pair\n",
    "        cf_min = cf\n",
    "    print np.sqrt(cf)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0020906791517911532"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(res_min['fun'])\n",
    "#a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0020906791517911532"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#cost_fun(res_min)\n",
    "res=res_min['x'].copy()\n",
    "cf_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-7.25  0.28  0.79 -6.7   1.82  2.04 -5.81  1.83  3.73  3.89  3.85  3.88\n",
      "  4.02  3.76  3.93  3.89  3.75  3.89  3.81  3.94  3.79  3.75  3.4   3.85\n",
      "  3.71  3.72  3.82  3.92  3.73  3.84  3.83  3.84  3.73  4.09  3.78  3.67\n",
      "  3.86  3.72  3.81  3.75  3.69  3.85  3.8   3.77  3.87  3.87  3.87  3.86\n",
      "  3.7   3.82  4.03  3.82  3.67  3.75  3.86  3.77  3.74  3.85  3.42  3.75\n",
      "  3.85  3.79  3.87]\n"
     ]
    }
   ],
   "source": [
    "#3D plot of the result\n",
    "print res[-o.shape[0]:].round(2)\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "p = res[:fixed_nodes.shape[0]*3].reshape((fixed_nodes.shape[0],3))[:fixed_nodes.shape[0]]\n",
    "#p[0,1]+=1\n",
    "p2 = res[:-len(offset_variable_to_pair_min)].reshape(((res.shape[0]-len(offset_variable_to_pair_min))/3,3))[fixed_nodes.shape[0]:]\n",
    "ax.scatter(p[:,0],p[:,1],p[:,2],c='b')\n",
    "for i in xrange(fixed_nodes.shape[0]):\n",
    "    ax.text(p[i,0],p[i,1],p[i,2],fixed_nodes[i])\n",
    "\n",
    "ax.scatter(B[:,0],B[:,1],B[:,2],c='g')\n",
    "ax.scatter(p2[:,0],p2[:,1],p2[:,2],c='y')\n",
    "#ax.scatter(pc[:,0],pc[:,1],pc[:,2],c='b')\n",
    "#ax.scatter(p2c[:,0],p2c[:,1],p2c[:,2],c='r')\n",
    "ax.set_aspect('equal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0.           0.           0.        ]\n",
      " [ 10.11481398   0.           0.        ]\n",
      " [  3.52651551  10.95072281   0.        ]\n",
      " [  6.5036523    8.27974315   4.98545859]\n",
      " [ 13.03070808  10.72102472   0.37880569]\n",
      " [ 16.12345458   1.66013333   0.67121005]\n",
      " [ 16.41303364   5.22995144   0.52341973]\n",
      " [  0.34356977   5.78397216   0.20109945]]\n",
      "[[  0.     0.     0.  ]\n",
      " [  9.97   0.     0.  ]\n",
      " [  3.15  11.16   0.  ]]\n"
     ]
    }
   ],
   "source": [
    "#Coordinates of first 8 nodes (==anchors)\n",
    "p_all = res[:24].reshape((8,3))\n",
    "print p_all\n",
    "print B\n",
    "#np.linalg.norm(p_all[20]-p_all[21])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.762853608096266"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#average offset\n",
    "res[-len(offset_variable_to_pair_min):].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4.16799159,  3.63648985,  4.03304079,  3.83795675,  4.02615586,\n",
       "        3.68629254,  4.03762013,  3.89848137,  4.18677463,  3.62661513,\n",
       "        4.02919902,  3.79128936,  3.24252253,  3.74993813,  3.54417684,\n",
       "        3.63720535,  4.21208742,  3.54548237,  4.18295844,  3.71217001,\n",
       "        4.06504594,  3.65841194,  4.2756098 ,  3.93173312,  3.3867485 ,\n",
       "        3.76147812,  3.18438827,  3.92609695])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print offsets\n",
    "res[-len(offset_variable_to_pair_min):]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#save the offsets if needed\n",
    "import scipy.io as sio\n",
    "#sio.savemat(\"offsets_outdoors_nobasepoints_given_longlongrun.mat\",{\"offset_variable_to_pair\":np.array(offset_variable_to_pair_min),'offsets':res_min[-len(offset_variable_to_pair_min):]})\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
