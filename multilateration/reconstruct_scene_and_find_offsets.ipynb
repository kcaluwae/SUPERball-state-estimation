{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib wx\n",
    "import superball_multilateration_barconstraints as smb\n",
    "import numpy as np \n",
    "import rospy\n",
    "import rosbag\n",
    "from matplotlib import pylab as plt\n",
    "plt.ion()\n",
    "from sklearn import linear_model, datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "topics = ['/bbb10/0x2017_0x1','/bbb10/0x2017_0x2','/bbb10/0x2017_0x4','/bbb10/0x2017_0x7','/bbb10/0x2017_0x8',\n",
    "          '/bbb10/0x2017_0xc','/bbb10/0x2017_0xd','/bbb10/0x2017_0xe','/bbb10/0x2017_0x10',\n",
    "         ]\n",
    "topics_node_to_node = np.array([[10,1],\n",
    "                               [10,2],\n",
    "                               [10,4],\n",
    "                               [10,7],\n",
    "                               [10,8],\n",
    "                                [10,12],\n",
    "                                [10,13],\n",
    "                                [10,14],\n",
    "                                [10,16]\n",
    "                               ],dtype=int)\n",
    "\n",
    "#topics_sensor = np.zeros(topics_node_to_node.shape,dtype=int)\n",
    "#for i in xrange(topics_node_to_node.shape[0]):\n",
    "#    topics_sensor[i] = (node_to_sensor[topics_node_to_node[i,0]],node_to_sensor[topics_node_to_node[i,1]])\n",
    "\n",
    "#1,2,4,7,8,10\n",
    "node_indices = {1:0,2:1,4:2,7:3,8:4,10:5,12:6,13:7,14:8,16:9}\n",
    "bag_names = []\n",
    "measured_distances = []\n",
    "node_to_sensor = []\n",
    "\n",
    "bag_names.append(\"FUN_PENDULUM_2015-08-14-16-25-39.bag\")\n",
    "node_to_sensor.append({1:1,2:5,4:3,7:6,8:4,10:2,12:9,13:13,14:14,16:16})\n",
    "\n",
    "bag_names.append(\"SWING_PENDULUM_2015-08-14-16-16-08.bag\")\n",
    "node_to_sensor.append({1:1,2:5,4:3,7:6,8:4,10:2,12:9,13:13,14:14,16:16})\n",
    "\n",
    "bag_names.append('2D_SWING_PENDULUM_2015-08-14-16-18-23.bag')\n",
    "node_to_sensor.append({1:1,2:5,4:3,7:6,8:4,10:2,12:9,13:13,14:14,16:16})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FUN_PENDULUM_2015-08-14-16-25-39.bag\n",
      "SWING_PENDULUM_2015-08-14-16-16-08.bag\n",
      "2D_SWING_PENDULUM_2015-08-14-16-18-23.bag\n"
     ]
    }
   ],
   "source": [
    "#process all bag files\n",
    "plt.close('all')\n",
    "bag_means = []\n",
    "bag_std = []\n",
    "bag_means_raw = []\n",
    "bag_stds_raw = []\n",
    "bag_means_nodes = []\n",
    "bag_std_nodes = []\n",
    "data_clean = []\n",
    "for n_i,n in enumerate(bag_names):\n",
    "    print n\n",
    "    bag = rosbag.Bag(n)\n",
    "    data = {}\n",
    "    topics_mean = np.zeros(len(topics))\n",
    "    topics_std = np.zeros(len(topics))\n",
    "    plt.figure()\n",
    "    d_supahclean = []\n",
    "    for i,t in enumerate(topics):\n",
    "        plt.subplot(3,3,i+1)\n",
    "        data = []\n",
    "        for m in bag.read_messages(topics=[t]):\n",
    "            data.append((m[1].header.stamp.to_sec(),m[1].data))\n",
    "        d = np.array(data)\n",
    "        d_clean = d[np.where((d[:,1]>3.5)&(d[:,1]<10))[0]] #remove bad measurements\n",
    "        if(d_clean.shape[0]>10):\n",
    "            model_ransac = linear_model.RANSACRegressor(linear_model.LinearRegression())\n",
    "            model_ransac.fit(np.arange(d_clean.shape[0]).reshape((-1,1)), d_clean)\n",
    "            inlier_mask = model_ransac.inlier_mask_\n",
    "            outlier_mask = np.logical_not(inlier_mask)\n",
    "            m = d_clean[inlier_mask,1].mean()\n",
    "            std = d_clean[inlier_mask,1].std()\n",
    "            d_outlier = d_clean[np.where((np.abs(d_clean[:,1]-m)<3*std))[0],:]\n",
    "            topics_mean[i] = d_outlier[:,1].mean()\n",
    "            topics_std[i] = d_outlier[:,1].std()\n",
    "            #plt.plot(d_clean)\n",
    "            #plt.plot(d_clean[inlier_mask])\n",
    "            #plt.plot(d_outlier[:,0]-d_outlier[0,0],d_outlier[:,1],'.')\n",
    "            #plt.plot(d_outlier[:,0]-d_outlier[0,0],d_outlier[:,1])\n",
    "            \n",
    "            d = d_outlier.copy()\n",
    "            good_data = []\n",
    "            good_data.append(d[0])\n",
    "            v_d = np.zeros(d.shape)\n",
    "            for i in xrange(1,d.shape[0]):\n",
    "                t_1 = good_data[-1][0]\n",
    "                t = d[i,0]\n",
    "                p_1 = good_data[-1][1]\n",
    "                p = d[i,1]\n",
    "                v = np.abs((p-p_1)/(t-t_1))\n",
    "                v_d[i]=v\n",
    "                if(v<1.5):\n",
    "                    good_data.append(d[i])\n",
    "            good_data=np.array(good_data)\n",
    "            plt.plot(d_outlier[:,0]-d_outlier[0,0],d_outlier[:,1],'+')\n",
    "            plt.plot(good_data[:,0]-d_outlier[0,0],good_data[:,1],'.')\n",
    "            plt.plot(good_data[:,0]-d_outlier[0,0],good_data[:,1],'-')\n",
    "            d_supahclean.append(good_data.copy())\n",
    "        else:\n",
    "            topics_mean[i] = 0\n",
    "            topics_std[i] = 0\n",
    "            d_supahclean.append(np.zeros((0,0)))\n",
    "    data_clean.append(d_supahclean)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#convert to clean datasets (>3 measurements), fixed rate\n",
    "meas = []\n",
    "for n_i,n in enumerate(bag_names):\n",
    "    data = data_clean[n_i]\n",
    "    t0 = np.min([d[0,0] for d in data])\n",
    "    tend = np.min([d[-1,0] for d in data])\n",
    "    timesteps = np.arange(t0,tend,0.2)\n",
    "    measurements = np.zeros((timesteps.shape[0],len(topics)))\n",
    "    \n",
    "    for t_i, t in enumerate(timesteps):\n",
    "        for j in xrange(len(topics)):\n",
    "            d = data[j]\n",
    "            #get all matching data\n",
    "            idx = np.where((d[:,0]>=t) & (d[:,0]<t+0.2))[0]\n",
    "            if(idx.shape>0):\n",
    "                measurements[t_i,j] = np.median(d[idx,1])\n",
    "            else:\n",
    "                measurements[t_i,j] = 0 \n",
    "    meas.append(measurements[np.where(np.sum((measurements>1) & (measurements<10),1)>=7)]) #how many valid measurements do we need?\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(51, 9)\n",
      "(41, 9)\n",
      "(61, 9)\n"
     ]
    }
   ],
   "source": [
    "for n_i,n in enumerate(bag_names):\n",
    "    plt.figure()\n",
    "    m = meas[n_i]\n",
    "    print m.shape\n",
    "    for i,t in enumerate(topics):\n",
    "        plt.subplot(3,3,i+1)\n",
    "        plt.plot(m[:,i],'.-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create \"variables\"\n",
    "def cost_function(x,y,m,o):\n",
    "    '''\n",
    "        Assumes x and y are Nx3, m and o are 1d vectors\n",
    "    '''\n",
    "    dist_xy = np.sqrt(np.sum((x-y)**2,1)) #1d vector\n",
    "    cost_per_element = (dist_xy-(m-o))**2\n",
    "    total_cost = cost_per_element.sum()\n",
    "    return total_cost\n",
    "\n",
    "def derivative_cost_function(x,y,m,o):\n",
    "    '''\n",
    "        Derivatives of the cost function wrt x,y and o\n",
    "    '''\n",
    "    dist_xy = np.sqrt(np.sum((x-y)**2,1)) #1d vector\n",
    "    factor = 2*(dist_xy-(m-o))/dist_xy\n",
    "    #derivative with respect to x\n",
    "    deriv_x = factor.reshape((-1,1))*(x-y)\n",
    "    #derivative with respect to y\n",
    "    deriv_y = -deriv_x\n",
    "    #derivative with respect to o\n",
    "    deriv_o = factor*dist_xy\n",
    "    return deriv_x, deriv_y, deriv_o\n",
    "def create_data(fixed_nodes,floating_nodes,measurement_pairs,measurements):\n",
    "    '''\n",
    "        fixed nodes: indices in measurement_pairs corresponding to fixed nodes\n",
    "        floating nodes: indices in measurement_paris correspond to floating nodes\n",
    "        measurements pairs: each column in measurements corresponds to a distance between two nodes as specified by the rows in this matrix\n",
    "        measurements: num_measurements x num pairs observed distances\n",
    "        \n",
    "    '''\n",
    "    num_fixed = fixed_nodes.shape[0]\n",
    "    num_floating = floating_nodes.shape[0]\n",
    "    measurement_pairs = measurement_pairs.copy()\n",
    "    \n",
    "    #DOF = num_fixed #number of coordinates to find\n",
    "    #num_offsets = num_fixed*num_floating#number of offset variables to find (vector rows = fixed, columns = floating -> ravel)\n",
    "    \n",
    "    constraints = []\n",
    "    \n",
    "    variables = []\n",
    "    offsets = []\n",
    "    \n",
    "    for v in fixed_nodes:\n",
    "        variables.append((v,-1))\n",
    "    \n",
    "    #N = [ [x y z]_fixed[0] ... [x y z]_fixed[num_fixed-1] [x y z]_float[0,meas[0]] ...[x y z]_float[0,meas[k]] [x y z]_float[1,meas[0]]...\n",
    "    floating_node_to_coordinate_indices = [] #contains the indices in N for each valid measurement of a floating node\n",
    "    for i in xrange(num_floating):\n",
    "        \n",
    "        #select all measurement pair columns to/from this node\n",
    "        node = floating_nodes[i]\n",
    "        \n",
    "        node_dist_idx = np.where((measurement_pairs[:,0] == node) | (measurement_pairs[:,1] == node))[0]\n",
    "        #print i\n",
    "        #print node_dist_idx\n",
    "        #select all relevant measurements (columns)\n",
    "        node_meas = measurements[:,node_dist_idx]\n",
    "        #only keep valid measurements \n",
    "        node_meas_check = (node_meas>1) & (node_meas<20) #conservative for now\n",
    "        node_valid_distances = node_meas_check.sum(1)\n",
    "        #indices in node_meas\n",
    "        #select valid rows with a\n",
    "        node_meas_valid = np.where((node_valid_distances>=3))[0] #only keep measurements with at least 4 valid distances\n",
    "        \n",
    "        for row_i,row in enumerate(node_meas_valid):\n",
    "            meas_row = measurements[row]\n",
    "            valid_cols = np.where(node_meas_check[row])[0]\n",
    "            valid_pairs = measurement_pairs[node_dist_idx[valid_cols],:]\n",
    "            meas_valid_row = meas_row[valid_cols]\n",
    "            #if(node==6):\n",
    "            #print node_dist_idx\n",
    "            #print valid_pairs\n",
    "            #print measurement_pairs[node_dist_idx[valid_cols],:]\n",
    "            #print \"\"\n",
    "            for col_i, col in enumerate(valid_cols):\n",
    "                pair = np.sort(valid_pairs[col_i])\n",
    "                \n",
    "                #make sure we have allocated a variable for each measurement\n",
    "                \n",
    "                if(pair[0] in fixed_nodes):\n",
    "                    if(not (pair[0],-1) in variables):\n",
    "                        variables.append((pair[0],-1))\n",
    "                elif(not (pair[0],row) in variables): #create new variable for this observation?\n",
    "                    variables.append((pair[0],row))\n",
    "                \n",
    "                if(pair[1] in fixed_nodes):\n",
    "                    if(not (pair[1],-1) in variables):\n",
    "                        variables.append((pair[0],-1))\n",
    "                elif(not tuple((pair[1],row)) in variables): #create new variable for this observation?\n",
    "                    variables.append((pair[1],row)) \n",
    "                #is there an existing offset variable for this measurement pair?\n",
    "                if(not tuple(pair) in offsets):\n",
    "                    offsets.append(tuple(pair))\n",
    "                    \n",
    "                if(pair[0] in fixed_nodes):\n",
    "                    v0 = (pair[0],-1)\n",
    "                else:\n",
    "                    v0 = (pair[0],row)\n",
    "                if(pair[1] in fixed_nodes):\n",
    "                    v1 = (pair[1],-1)\n",
    "                else:\n",
    "                    v1 = (pair[1],row)\n",
    "                \n",
    "                if(pair[0] in floating_nodes and pair[1] in floating_nodes):\n",
    "                        print \"floating node to floating node measurements\"\n",
    "                \n",
    "                m = meas_row[node_dist_idx[col]]\n",
    "                constraints.append((variables.index(v0),variables.index(v1),m,offsets.index(tuple(pair))))\n",
    "                \n",
    "                    \n",
    "\n",
    "        #floating_node_to_coordinate_indices.append(node_meas_valid+DOF)    \n",
    "        #DOF += node_meas_valid.shape[0] #every valid measurement adds a coordinate (3D)\n",
    "    \n",
    "    DOF = len(variables)\n",
    "    num_offsets = len(offsets)\n",
    "    #print variables\n",
    "    #print offsets\n",
    "    \n",
    "    N_to_CSTR_X = np.zeros((len(constraints),DOF))\n",
    "    N_to_CSTR_Y = np.zeros(N_to_CSTR_X.shape)\n",
    "    o_to_CSTR = np.zeros((len(constraints),num_offsets))\n",
    "    #print num_offsets\n",
    "    m = np.zeros(len(constraints))\n",
    "    for i in xrange(len(constraints)):\n",
    "        N_to_CSTR_X[i,constraints[i][0]] = 1\n",
    "        N_to_CSTR_Y[i,constraints[i][1]] = 1\n",
    "        m[i] = constraints[i][2]\n",
    "        #print constraints[i]\n",
    "        o_to_CSTR[i,constraints[i][3]] = 1\n",
    "    \n",
    "    \n",
    "    \n",
    "    def deriv_func(N,o):\n",
    "        X = N_to_CSTR_X.dot(N)\n",
    "        Y = N_to_CSTR_Y.dot(N)\n",
    "        O = o_to_CSTR.dot(o.reshape((num_offsets,1))) \n",
    "        dX,dY,dO = derivative_cost_function(X,Y,m.ravel(),O.ravel())\n",
    "        dN = N_to_CSTR_X.T.dot(dX) +  N_to_CSTR_Y.T.dot(dY)\n",
    "        dN[0,:] = 0\n",
    "        dN[1,1:] = 0\n",
    "        dN[2,2] = 0\n",
    "        do = o_to_CSTR.T.dot(dO.reshape((-1,1))).ravel()\n",
    "        return dN,do\n",
    "    \n",
    "    def cost_func(N,o):\n",
    "        X = N_to_CSTR_X.dot(N)\n",
    "        Y = N_to_CSTR_Y.dot(N)\n",
    "        O = o_to_CSTR.dot(o.reshape((num_offsets,1))) \n",
    "        return cost_function(X,Y,m.ravel(),O.ravel())\n",
    "        \n",
    "    \n",
    "    #create m vector\n",
    "    return deriv_func,cost_func, len(variables), len(offsets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4823.47449355\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 6.572584\n",
      "         Iterations: 201\n",
      "         Function evaluations: 230\n",
      "         Gradient evaluations: 230\n",
      "6.57258429849\n"
     ]
    }
   ],
   "source": [
    "#WORKING VERSION\n",
    "fixed_nodes = np.array([1,2,4,7,8,12,13,16],dtype=int)\n",
    "floating_nodes = np.array([10,],dtype=int)\n",
    "dist_pairs = np.array([[1,10],[2,10],[4,10],[7,10],[8,10],[12,10],[13,10],[16,10]],dtype=int)\n",
    "\n",
    "m = np.vstack((meas[0][::2],meas[1][::3]))[:,(0,1,2,3,4,5,6,8)]\n",
    "#m = np.hstack((m,np.ones((m.shape[0],1))*1.36))\n",
    "df,cf,DOF,num_offsets = create_data(fixed_nodes,floating_nodes,dist_pairs,m)\n",
    "\n",
    "N,o = np.random.random((DOF,3))*5,np.zeros(num_offsets)+3.5\n",
    "N[0] = 0\n",
    "N[1,1:] = 0\n",
    "N[2,2] = 0     \n",
    "B=np.array([[ 0.,          0.,          0.        ],\n",
    "                 [ 1.36230428,  0.,          0.        ],\n",
    "                 [ 2.47776388,  1.21785478,  0.        ]])\n",
    "N[:3] = B\n",
    "\n",
    "dN,do = df(N,o)\n",
    "print cf(N,o)\n",
    "\n",
    "import scipy.optimize as so\n",
    "Nf = N.ravel()\n",
    "X_initial = np.hstack((Nf,o))\n",
    "def cost_fun(x):\n",
    "    Nt = x[:-o.shape[0]].reshape((DOF,3))\n",
    "    Nt[:3] = B\n",
    "    reg = 0*0.05*np.sum((x[-o.shape[0]:]-3.5)**2)\n",
    "    return cf(Nt ,x[-o.shape[0]:]*0+3.5)+reg\n",
    "def cost_grad(x):\n",
    "    dN,do = df(x[:-o.shape[0]].reshape((DOF,3)),x[-o.shape[0]:])\n",
    "    dN[:3] = 0\n",
    "    do[:] = 0\n",
    "    #do += 0.05*2*(x[-o.shape[0]:]-3.5)\n",
    "    return np.hstack((dN.ravel(),do))\n",
    "\n",
    "res = so.fmin_bfgs(cost_fun,X_initial,fprime=cost_grad,disp=10,gtol=1e-7)\n",
    "print cost_fun(res)\n",
    "#    #print res[:-o.shape[0]].reshape((DOF,3))[:N_target.shape[0]].round(2)\n",
    "#    #print N_target.round(2)\n",
    "#    #print np.sort(res[-o.shape[0]:].round(2))\n",
    "#    #print np.sort(o_target.round(2))\n",
    "#all_results.append((o_target.copy(),res[-o.shape[0]:].copy(),cost_fun(res)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.  ,  0.  ,  0.  ],\n",
       "       [ 1.36,  0.  ,  0.  ],\n",
       "       [ 2.48,  1.22,  0.  ],\n",
       "       [-0.58,  2.85,  1.79],\n",
       "       [ 1.08,  2.94,  1.84],\n",
       "       [-0.62, -0.99,  2.17],\n",
       "       [ 1.87,  0.5 ,  3.04],\n",
       "       [-0.8 ,  1.44,  3.69]])"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[:-o.shape[0]].reshape((DOF,3))[:fixed_nodes.shape[0]].round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 3.5  3.5  3.5  3.5  3.5  3.5  3.5  3.5]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<mpl_toolkits.mplot3d.art3d.Patch3DCollection at 0x7fee009be3d0>"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print res[-o.shape[0]:].round(2)\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "p = res[:-dist_pairs.shape[0]].reshape((DOF,3))[:fixed_nodes.shape[0]]\n",
    "p2 = res[:-dist_pairs.shape[0]].reshape((DOF,3))[fixed_nodes.shape[0]:][-meas[1][::3].shape[0]:]\n",
    "ax.scatter(p[:,0],p[:,1],p[:,2],c='y')\n",
    "ax.scatter(p2[:,0],p2[:,1],p2[:,2],c='g')\n",
    "ax.scatter(pc[:,0],pc[:,1],pc[:,2],c='b')\n",
    "ax.scatter(p2c[:,0],p2c[:,1],p2c[:,2],c='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#pc,p2c = p.copy(),p2.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3754.48211893\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.663313\n",
      "         Iterations: 386\n",
      "         Function evaluations: 399\n",
      "         Gradient evaluations: 399\n",
      "0.663313348375\n"
     ]
    }
   ],
   "source": [
    "#WORKING VERSION\n",
    "fixed_nodes = np.array([1,4,7,13],dtype=int)\n",
    "floating_nodes = np.array([10,],dtype=int)\n",
    "dist_pairs = np.array([[1,10],[4,10],[7,10],[13,10]],dtype=int)\n",
    "                       #np.array([[1,10],[2,10],[4,10],[7,10],[8,10],[12,10],[13,10],[16,10]],dtype=int)\n",
    "\n",
    "m = np.vstack((meas[0][::2],meas[1][::3]))[:,(0,2,3,6)]#[:,(0,1,2,3,4,5,6,8)]\n",
    "#m = np.hstack((m,np.ones((m.shape[0],1))*1.36))\n",
    "df,cf,DOF,num_offsets = create_data(fixed_nodes,floating_nodes,dist_pairs,m)\n",
    "\n",
    "N,o = np.random.random((DOF,3))*5,np.zeros(num_offsets)+3.5\n",
    "N[0] = 0\n",
    "N[1,1:] = 0\n",
    "N[2,2] = 0     \n",
    "B=np.array([[ 0.,          0.,          0.        ],\n",
    "                 [ 1.36230428,  0.,          0.        ],\n",
    "                 [ 2.47776388,  1.21785478,  0.        ]])\n",
    "N[:3] = B\n",
    "\n",
    "dN,do = df(N,o)\n",
    "print cf(N,o)\n",
    "\n",
    "import scipy.optimize as so\n",
    "Nf = N.ravel()\n",
    "X_initial = np.hstack((Nf,o))\n",
    "def cost_fun(x):\n",
    "    Nt = x[:-o.shape[0]].reshape((DOF,3))\n",
    "    #Nt[:3] = B\n",
    "    reg = 0.05*np.sum((x[-o.shape[0]:]-3.5)**2)\n",
    "    return cf(Nt ,x[-o.shape[0]:])+reg\n",
    "def cost_grad(x):\n",
    "    dN,do = df(x[:-o.shape[0]].reshape((DOF,3)),x[-o.shape[0]:])\n",
    "    #dN[:3] = 0\n",
    "    #do[:] = 0\n",
    "    do += 0.05*2*(x[-o.shape[0]:]-3.5)\n",
    "    return np.hstack((dN.ravel(),do))\n",
    "\n",
    "res = so.fmin_bfgs(cost_fun,X_initial,fprime=cost_grad,disp=10,gtol=1e-7)\n",
    "print cost_fun(res)\n",
    "#    #print res[:-o.shape[0]].reshape((DOF,3))[:N_target.shape[0]].round(2)\n",
    "#    #print N_target.round(2)\n",
    "#    #print np.sort(res[-o.shape[0]:].round(2))\n",
    "#    #print np.sort(o_target.round(2))\n",
    "#all_results.append((o_target.copy(),res[-o.shape[0]:].copy(),cost_fun(res)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.  ,  0.  ,  0.  ],\n",
       "       [ 3.19,  0.  ,  0.  ],\n",
       "       [ 1.01,  2.66,  0.  ],\n",
       "       [ 2.25,  0.71,  2.34]])"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[:-o.shape[0]].reshape((DOF,3))[:fixed_nodes.shape[0]].round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 3.75  3.65  3.8   3.61]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<mpl_toolkits.mplot3d.art3d.Patch3DCollection at 0x7fee0d6bbf90>"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print res[-o.shape[0]:].round(2)\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "p = res[:-dist_pairs.shape[0]].reshape((DOF,3))[:fixed_nodes.shape[0]]\n",
    "p2 = res[:-dist_pairs.shape[0]].reshape((DOF,3))[fixed_nodes.shape[0]:][-meas[1][::3].shape[0]:]\n",
    "ax.scatter(p[:,0],p[:,1],p[:,2],c='b')\n",
    "ax.scatter(p2[:,0],p2[:,1],p2[:,2],c='y')\n",
    "#ax.scatter(pc[:,0],pc[:,1],pc[:,2],c='b')\n",
    "#ax.scatter(p2c[:,0],p2c[:,1],p2c[:,2],c='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.7812198989347681"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(pc[0]-pc[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "841.805743931\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.453570\n",
      "         Iterations: 330\n",
      "         Function evaluations: 371\n",
      "         Gradient evaluations: 371\n",
      "0.453570444261\n"
     ]
    }
   ],
   "source": [
    "fixed_nodes = np.array([1,2,4,7,8,16],dtype=int)\n",
    "floating_nodes = np.array([10,],dtype=int)\n",
    "dist_pairs = np.array([[1,10],[2,10],[4,10],[7,10],[8,10],[16,10]],dtype=int)\n",
    "\n",
    "m = meas[2][::5][:,(0,1,2,3,4,5,6,8)]\n",
    "df,cf,DOF,num_offsets = create_data(fixed_nodes,floating_nodes,dist_pairs,m)\n",
    "\n",
    "N,o = np.random.random((DOF,3))*5,np.zeros(num_offsets)+3.5\n",
    "N[0] = 0\n",
    "N[1,1:] = 0\n",
    "N[2,2] = 0     \n",
    "B=np.array([[ 0.,          0.,          0.        ],\n",
    "                 [ 1.36230428,  0.,          0.        ],\n",
    "                 [ 2.47776388,  1.21785478,  0.        ]])\n",
    "N[:3] = B\n",
    "\n",
    "dN,do = df(N,o)\n",
    "print cf(N,o)\n",
    "\n",
    "import scipy.optimize as so\n",
    "Nf = N.ravel()\n",
    "X_initial = Nf.copy()\n",
    "def cost_fun(x):\n",
    "    Nt = x.reshape((DOF,3))\n",
    "    Nt[:3] = B\n",
    "    return cf(Nt ,o)\n",
    "def cost_grad(x):\n",
    "    dN,do = df(x.reshape((DOF,3)),o)\n",
    "    dN[:3] = 0\n",
    "    \n",
    "    return dN.ravel()\n",
    "\n",
    "res = so.fmin_bfgs(cost_fun,X_initial,fprime=cost_grad,disp=10,gtol=1e-5)\n",
    "print cost_fun(res)\n",
    "#    #print res[:-o.shape[0]].reshape((DOF,3))[:N_target.shape[0]].round(2)\n",
    "#    #print N_target.round(2)\n",
    "#    #print np.sort(res[-o.shape[0]:].round(2))\n",
    "#    #print np.sort(o_target.round(2))\n",
    "#all_results.append((o_target.copy(),res[-o.shape[0]:].copy(),cost_fun(res)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.  ,  0.  ,  0.  ],\n",
       "       [ 1.36,  0.  ,  0.  ],\n",
       "       [ 2.48,  1.22,  0.  ],\n",
       "       [ 0.01,  2.73,  0.5 ],\n",
       "       [ 0.83,  2.11,  3.6 ],\n",
       "       [-0.67, -0.89,  2.53]])"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.reshape((DOF,3))[:fixed_nodes.shape[0]].round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(44, 9)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "for i in xrange(9):\n",
    "    plt.subplot(3,3,i+1)\n",
    "    plt.plot(meas[0][:,i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
