{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib wx\n",
    "import superball_multilateration_barconstraints as smb\n",
    "import numpy as np \n",
    "import rospy\n",
    "import rosbag\n",
    "from matplotlib import pylab as plt\n",
    "plt.ion()\n",
    "from sklearn import linear_model, datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "topics = ['/bbb2/0x2017_0xd','/bbb2/0x2017_0xe','/bbb2/0x2017_0xf','/bbb2/0x2017_0x10',\n",
    "          '/bbb2/0x2717_0xd','/bbb2/0x2717_0xe','/bbb2/0x2717_0xf','/bbb2/0x2717_0x10',\n",
    "          '/bbb4/0x2017_0xd','/bbb4/0x2017_0xe','/bbb4/0x2017_0xf','/bbb4/0x2017_0x10',\n",
    "          '/bbb4/0x2717_0xd','/bbb4/0x2717_0xe','/bbb4/0x2717_0xf','/bbb4/0x2717_0x10',\n",
    "          '/bbb6/0x2017_0xd','/bbb6/0x2017_0xe','/bbb6/0x2017_0xf','/bbb6/0x2017_0x10',\n",
    "          '/bbb6/0x2717_0xd','/bbb6/0x2717_0xe','/bbb6/0x2717_0xf','/bbb6/0x2717_0x10',\n",
    "          '/bbb8/0x2017_0xd','/bbb8/0x2017_0xe','/bbb8/0x2017_0xf','/bbb8/0x2017_0x10',\n",
    "          '/bbb8/0x2717_0xd','/bbb8/0x2717_0xe','/bbb8/0x2717_0xf','/bbb8/0x2717_0x10',\n",
    "          '/bbb10/0x2017_0xd','/bbb10/0x2017_0xe','/bbb10/0x2017_0xf','/bbb10/0x2017_0x10',\n",
    "          '/bbb10/0x2717_0xd','/bbb10/0x2717_0xe','/bbb10/0x2717_0xf','/bbb10/0x2717_0x10',\n",
    "          '/bbb12/0x2017_0xd','/bbb12/0x2017_0xe','/bbb12/0x2017_0xf','/bbb12/0x2017_0x10',\n",
    "          '/bbb12/0x2717_0xd','/bbb12/0x2717_0xe','/bbb12/0x2717_0xf','/bbb12/0x2717_0x10'\n",
    "         ]\n",
    "topics_node_to_node = np.array([[2,13],\n",
    "                               [2,14],\n",
    "                               [2,15],\n",
    "                               [2,16],\n",
    "                               [1,13],\n",
    "                                [1,14],\n",
    "                                [1,15],\n",
    "                                [1,16],\n",
    "                                \n",
    "                                [4,13],\n",
    "                               [4,14],\n",
    "                               [4,15],\n",
    "                               [4,16],\n",
    "                               [3,13],\n",
    "                                [3,14],\n",
    "                                [3,15],\n",
    "                                [3,16],\n",
    "                                \n",
    "                                [6,13],\n",
    "                               [6,14],\n",
    "                               [6,15],\n",
    "                               [6,16],\n",
    "                               [5,13],\n",
    "                                [5,14],\n",
    "                                [5,15],\n",
    "                                [5,16],\n",
    "                                \n",
    "                                [8,13],\n",
    "                               [8,14],\n",
    "                               [8,15],\n",
    "                               [8,16],\n",
    "                               [7,13],\n",
    "                                [7,14],\n",
    "                                [7,15],\n",
    "                                [7,16],\n",
    "                                \n",
    "                                [10,13],\n",
    "                               [10,14],\n",
    "                               [10,15],\n",
    "                               [10,16],\n",
    "                               [9,13],\n",
    "                                [9,14],\n",
    "                                [9,15],\n",
    "                                [9,16],\n",
    "                                \n",
    "                                [12,13],\n",
    "                               [12,14],\n",
    "                               [12,15],\n",
    "                               [12,16],\n",
    "                               [11,13],\n",
    "                                [11,14],\n",
    "                                [11,15],\n",
    "                                [11,16],\n",
    "                               ],dtype=int) #corresponds to topics above\n",
    "\n",
    "#topics_sensor = np.zeros(topics_node_to_node.shape,dtype=int)\n",
    "#for i in xrange(topics_node_to_node.shape[0]):\n",
    "#    topics_sensor[i] = (node_to_sensor[topics_node_to_node[i,0]],node_to_sensor[topics_node_to_node[i,1]])\n",
    "\n",
    "#1,2,4,7,8,10\n",
    "#node_indices = {1:0,2:1,13:2,14:3,15:4,16:5} #node index in distance vectors\n",
    "bag_names = []\n",
    "measured_distances = []\n",
    "node_to_sensor = []\n",
    "\n",
    "#bag_names.append(\"2015-08-27-13-25-56.bag\")\n",
    "#node_to_sensor.append({1:1,2:5,13:13,14:14,16:16})\n",
    "\n",
    "bag_names.append(\"outdoor_ranging_2015-09-22-15-41-32.bag\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outdoor_ranging_2015-09-22-15-41-32.bag\n"
     ]
    }
   ],
   "source": [
    "#process all bag files\n",
    "plt.close('all')\n",
    "bag_means = []\n",
    "bag_std = []\n",
    "bag_means_raw = []\n",
    "bag_stds_raw = []\n",
    "bag_means_nodes = []\n",
    "bag_std_nodes = []\n",
    "data_clean = []\n",
    "for n_i,n in enumerate(bag_names):\n",
    "    print n\n",
    "    bag = rosbag.Bag(n)\n",
    "    data = {}\n",
    "    topics_mean = np.zeros(len(topics))\n",
    "    topics_std = np.zeros(len(topics))\n",
    "    plt.figure()\n",
    "    d_supahclean = []\n",
    "    for i,t in enumerate(topics):\n",
    "        plt.subplot(4,12,i+1)\n",
    "        data = []\n",
    "        for m in bag.read_messages(topics=[t]):\n",
    "            data.append((m[1].header.stamp.to_sec(),m[1].data))\n",
    "        d = np.array(data)\n",
    "        try:\n",
    "            d_clean = d[np.where((d[:,1]>3.5)&(d[:,1]<20))[0]] #remove bad measurements\n",
    "        except:\n",
    "            d_supahclean.append(np.zeros((1,2)))\n",
    "            print \"err\"\n",
    "            continue\n",
    "        if(d_clean.shape[0]>10):\n",
    "            model_ransac = linear_model.RANSACRegressor(linear_model.LinearRegression())\n",
    "            model_ransac.fit(np.arange(d_clean.shape[0]).reshape((-1,1)), d_clean)\n",
    "            inlier_mask = model_ransac.inlier_mask_\n",
    "            outlier_mask = np.logical_not(inlier_mask)\n",
    "            m = d_clean[inlier_mask,1].mean()\n",
    "            std = d_clean[inlier_mask,1].std()\n",
    "            d_outlier = d_clean[np.where((np.abs(d_clean[:,1]-m)<3*std))[0],:]\n",
    "            topics_mean[i] = d_outlier[:,1].mean()\n",
    "            topics_std[i] = d_outlier[:,1].std()\n",
    "            #plt.plot(d_clean)\n",
    "            #plt.plot(d_clean[inlier_mask])\n",
    "            #plt.plot(d_outlier[:,0]-d_outlier[0,0],d_outlier[:,1],'.')\n",
    "            #plt.plot(d_outlier[:,0]-d_outlier[0,0],d_outlier[:,1])\n",
    "            \n",
    "            d = d_outlier.copy()\n",
    "            good_data = []\n",
    "            good_data.append(d[0])\n",
    "            v_d = np.zeros(d.shape)\n",
    "            for i in xrange(1,d.shape[0]):\n",
    "                t_1 = good_data[-1][0]\n",
    "                t = d[i,0]\n",
    "                p_1 = good_data[-1][1]\n",
    "                p = d[i,1]\n",
    "                v = np.abs((p-p_1)/(t-t_1))\n",
    "                v_d[i]=v\n",
    "                if(v<1.5):\n",
    "                    good_data.append(d[i])\n",
    "            good_data=np.array(good_data)\n",
    "            plt.plot(d_outlier[:,0]-d_outlier[0,0],d_outlier[:,1],'+')\n",
    "            plt.plot(good_data[:,0]-d_outlier[0,0],good_data[:,1],'.')\n",
    "            plt.plot(good_data[:,0]-d_outlier[0,0],good_data[:,1],'-')\n",
    "            d_supahclean.append(good_data.copy())\n",
    "        else:\n",
    "            topics_mean[i] = 0\n",
    "            topics_std[i] = 0\n",
    "            d_supahclean.append(np.zeros((1,2)))\n",
    "    data_clean.append(d_supahclean)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/numpy/core/_methods.py:59: RuntimeWarning: Mean of empty slice.\n",
      "  warnings.warn(\"Mean of empty slice.\", RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "#convert to clean datasets (>3 measurements), fixed rate\n",
    "meas = []\n",
    "for n_i,n in enumerate(bag_names):\n",
    "    data = data_clean[n_i]\n",
    "    t0 = np.max([d[0,0] for d in data[:8]])\n",
    "    tend = np.min([d[-1,0] for d in data[:8]])\n",
    "    timesteps = np.arange(t0,tend,0.2)\n",
    "    measurements = np.zeros((timesteps.shape[0],len(topics)))\n",
    "    \n",
    "    for t_i, t in enumerate(timesteps):\n",
    "        for j in xrange(len(topics)):\n",
    "            d = data[j]\n",
    "            #get all matching data\n",
    "            idx = np.where((d[:,0]>=t) & (d[:,0]<t+0.2))[0]\n",
    "            if(idx.shape>0):\n",
    "                measurements[t_i,j] = np.median(d[idx,1])\n",
    "            else:\n",
    "                measurements[t_i,j] = 0 \n",
    "    meas.append(measurements[np.where(np.sum((measurements[:,:4]>1) & (measurements[:,:4]<20),1)>3)]) #how many valid measurements do we need?\n",
    "    #TODO: for multiple nodes, make sure each one has at least 3 (or 4 is better) ranging measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "for i in xrange(12):\n",
    "    plt.subplot(3,4,i+1)\n",
    "    plt.plot(meas[0][:,i*4:(i+1)*4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4.18787562,  3.58978245,  4.12752976,  3.73947614])"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[-4:]\n",
    "#array([ 4.13215675,  3.67599784,  4.18511672,  3.83472233])\n",
    "#array([ 4.22836493,  3.80866668,  4.07504397,  3.75225553])\n",
    "#array([ 4.18787562,  3.58978245,  4.12752976,  3.73947614]) #0.15 #[15,13,16,14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 4.19  3.59  4.13  3.74]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<mpl_toolkits.mplot3d.art3d.Patch3DCollection at 0x7f30d04f80d0>"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print res[-o.shape[0]:].round(2)\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "p = res[:-dist_pairs.shape[0]].reshape((DOF,3))[:fixed_nodes.shape[0]]\n",
    "p2 = res[:-dist_pairs.shape[0]].reshape((DOF,3))[fixed_nodes.shape[0]:]\n",
    "ax.scatter(p[:,0],p[:,1],p[:,2],c='b')\n",
    "for i in xrange(fixed_nodes.shape[0]):\n",
    "    ax.text(p[i,0],p[i,1],p[i,2],fixed_nodes[i])\n",
    "\n",
    "ax.scatter(p2[:,0],p2[:,1],p2[:,2],c='y')\n",
    "#ax.scatter(pc[:,0],pc[:,1],pc[:,2],c='b')\n",
    "#ax.scatter(p2c[:,0],p2c[:,1],p2c[:,2],c='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  0.        ,  0.        ],\n",
       "       [-5.35      ,  0.        ,  0.        ],\n",
       "       [ 0.96      , -2.35      ,  0.        ],\n",
       "       [-2.71297727, -0.617745  , -2.3072566 ]])"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p\n",
    "#array([[ 0.        ,  0.        ,  0.        ],\n",
    "#       [-5.35      ,  0.        ,  0.        ],\n",
    "#       [ 0.96      , -2.35      ,  0.        ],\n",
    "#       [-2.71297727, -0.617745  , -2.3072566 ]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  3.66324529,  3.30318086,  5.90031792],\n",
       "       [ 3.66324529,  0.        ,  4.74821996,  3.60090027],\n",
       "       [ 3.30318086,  4.74821996,  0.        ,  7.24703045],\n",
       "       [ 5.90031792,  3.60090027,  7.24703045,  0.        ]])"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scipy.spatial as ss\n",
    "ss.distance.squareform(ss.distance.pdist(p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 4.19  3.59  4.13  3.74]\n"
     ]
    }
   ],
   "source": [
    "print res[-o.shape[0]:].round(2)\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "for it in xrange(len(resall)):\n",
    "    p = resall[it][:-dist_pairs.shape[0]].reshape((DOF,3))[:fixed_nodes.shape[0]]\n",
    "    #p2 = res[:-dist_pairs.shape[0]].reshape((DOF,3))[fixed_nodes.shape[0]:]\n",
    "    ax.scatter(p[:,0],p[:,1],p[:,2],c='b')\n",
    "for i in xrange(fixed_nodes.shape[0]):\n",
    "    ax.text(p[i,0],p[i,1],p[i,2],fixed_nodes[i])\n",
    "\n",
    "#ax.scatter(p2[:,0],p2[:,1],p2[:,2],c='y')\n",
    "#ax.scatter(pc[:,0],pc[:,1],pc[:,2],c='b')\n",
    "#ax.scatter(p2c[:,0],p2c[:,1],p2c[:,2],c='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#create \"variables\"\n",
    "def cost_function(x,y,m,o):\n",
    "    '''\n",
    "        Assumes x and y are Nx3, m and o are 1d vectors\n",
    "    '''\n",
    "    dist_xy = np.sqrt(np.sum((x-y)**2,1)) #1d vector\n",
    "    cost_per_element = (dist_xy-(m-o))**2\n",
    "    total_cost = cost_per_element.sum()\n",
    "    return total_cost\n",
    "\n",
    "def derivative_cost_function(x,y,m,o):\n",
    "    '''\n",
    "        Derivatives of the cost function wrt x,y and o\n",
    "    '''\n",
    "    dist_xy = np.sqrt(np.sum((x-y)**2,1)) #1d vector\n",
    "    factor = 2*(dist_xy-(m-o))/dist_xy\n",
    "    #derivative with respect to x\n",
    "    deriv_x = factor.reshape((-1,1))*(x-y)\n",
    "    #derivative with respect to y\n",
    "    deriv_y = -deriv_x\n",
    "    #derivative with respect to o\n",
    "    deriv_o = factor*dist_xy\n",
    "    return deriv_x, deriv_y, deriv_o\n",
    "def create_data(fixed_nodes,floating_nodes,measurement_pairs,measurements):\n",
    "    '''\n",
    "        fixed nodes: indices in measurement_pairs corresponding to fixed nodes\n",
    "        floating nodes: indices in measurement_paris correspond to floating nodes\n",
    "        measurements pairs: each column in measurements corresponds to a distance between two nodes as specified by the rows in this matrix\n",
    "        measurements: num_measurements x num pairs observed distances\n",
    "        \n",
    "    '''\n",
    "    num_fixed = fixed_nodes.shape[0]\n",
    "    num_floating = floating_nodes.shape[0]\n",
    "    num_measurements = measurements.shape[0]\n",
    "    measurement_pairs = measurement_pairs.copy()\n",
    "    \n",
    "    floating_to_fixed = {} #contains an array of indices in measurement_pairs for each node\n",
    "    floating_to_floating = {} #similar\n",
    "    bars = {1:(2,1.37),3:(4,1.37),5:(6,1.37),7:(8,1.37),9:(10,1.37),11:(12,1.37)} #nodes with bar connections: FROM: (TO,LENGTH)\n",
    "    \n",
    "    #for each floating node, find the measurement pairs to fixed nodes\n",
    "    for node_idx, node in enumerate(floating_nodes):\n",
    "        #get measurement columns corresponding to this node (to/from)        \n",
    "        node_dist_idx = np.where((measurement_pairs[:,0] == node) | (measurement_pairs[:,1] == node))[0]\n",
    "        #create new array\n",
    "        floating_to_fixed[node] = []        \n",
    "        for i in node_dist_idx:\n",
    "            if(measurement_pairs[i,0] in fixed_nodes or measurement_pairs[i,1] in fixed_nodes):\n",
    "                #found one\n",
    "                floating_to_fixed[node].append(i)\n",
    "                \n",
    "    #for each floating node, find the measurement pairs to other floating nodes\n",
    "    for node_idx, node in enumerate(floating_nodes):\n",
    "        #get measurement columns corresponding to this node (to/from)        \n",
    "        node_dist_idx = np.where((measurement_pairs[:,0] == node) | (measurement_pairs[:,1] == node))[0]\n",
    "        #create new array\n",
    "        floating_to_floating[node] = []        \n",
    "        for pair_idx in node_dist_idx:\n",
    "            #to prevent doubles, we only add pairs originating FROM this node TO another floating node\n",
    "            if((measurement_pairs[pair_idx,0] == node) and measurement_pairs[pair_idx,1] in floating_nodes):\n",
    "                #found one\n",
    "                floating_to_floating[node].append(pair_idx)\n",
    "    \n",
    "    \n",
    "    #Find all the floating node positions with enough measurements for ranging\n",
    "    #enough means more than 3 valid measurements to fixed nodes\n",
    "    floating_valid_points = np.zeros((num_measurements,num_floating),dtype=bool)\n",
    "    measurements_valid = (measurements>1) & (measurements<20) #this matrix contains a one for each valid measurements\n",
    "    #a one in the above matrix indicates that there are enough valid measurements between a floating node and fixed nodes available for the \n",
    "    #columns correspond to indices in floating_nodes\n",
    "    for node_idx, node in enumerate(floating_nodes):\n",
    "        for timestep_idx in xrange(num_measurements):\n",
    "            #get all measurements to fixed nodes from this node\n",
    "            to_fixed = floating_to_fixed[node]\n",
    "            valid_cnt = 0\n",
    "            for pair_idx in to_fixed:\n",
    "                if(measurements_valid[timestep_idx,pair_idx]):\n",
    "                    #this is a valid measurement, use it\n",
    "                    valid_cnt += 1\n",
    "            if(valid_cnt >= 4):\n",
    "                #we can estimate this location at this timestep\n",
    "                floating_valid_points[timestep_idx,node_idx] = True\n",
    "\n",
    "    #we now know all the valid coordinates to estimate, so we are ready to create constraints\n",
    "        \n",
    "    #print floating_to_fixed\n",
    "    #print floating_to_floating\n",
    "        \n",
    "    #create distance constraints between floating nodes and fixed nodes for all valid time steps with valid measurements per floating node\n",
    "    constraints = []\n",
    "    \n",
    "    for timestep_idx in xrange(num_measurements): #iterate over time steps\n",
    "        for node_idx, node in enumerate(floating_nodes): #iterate over nodes\n",
    "            if(floating_valid_points[timestep_idx,node_idx]):\n",
    "                #This is a valid measurement timestep, \n",
    "                #add a constraint for each valid measurement to the respective anchor.\n",
    "                to_fixed = floating_to_fixed[node]\n",
    "                for pair_idx in to_fixed:\n",
    "                    if(measurements_valid[timestep_idx,pair_idx]):\n",
    "                        constraints.append((\"float_to_fixed\",\n",
    "                                            measurement_pairs[pair_idx],\n",
    "                                            measurements[timestep_idx,pair_idx],\n",
    "                                            timestep_idx))\n",
    "                #add constraints to other valid floating nodes\n",
    "                to_floating = floating_to_floating[node]\n",
    "                for pair_idx in to_floating:\n",
    "                    if(measurements_valid[timestep_idx,pair_idx]):\n",
    "                        pair = measurement_pairs[pair_idx]\n",
    "                        from_ = np.where(floating_nodes == pair[0])[0][0]\n",
    "                        to_ = np.where(floating_nodes == pair[1])[0][0]\n",
    "                        if(floating_valid_points[timestep_idx,from_] and floating_valid_points[timestep_idx,to_]): #make sure destination node is valid at the current timestep\n",
    "                            \n",
    "                            constraints.append((\"float_to_float\",\n",
    "                                            measurement_pairs[pair_idx],\n",
    "                                            measurements[timestep_idx,pair_idx],\n",
    "                                            timestep_idx))\n",
    "                        \n",
    "                #add bar constraints\n",
    "                if(node in bars):\n",
    "                    b = bars[node]\n",
    "                    bar_node = b[0]\n",
    "                    #check whether destination node location is valid at this timestep\n",
    "                    if(floating_valid_points[timestep_idx,np.where(floating_nodes == bar_node)[0][0]]):\n",
    "                        #ok, we can add the constraint\n",
    "                        constraints.append((\"bar\",\n",
    "                                            [node,bar_node],\n",
    "                                            b[1],\n",
    "                                           timestep_idx))\n",
    "    \n",
    "    #create variables (this is the fun part)\n",
    "    variable_to_node = [] #indicates which variable corresponds to which node\n",
    "    for n in fixed_nodes:\n",
    "        variable_to_node.append(n) #first indices are fixed nodes\n",
    "    for timestep_idx in xrange(num_measurements): #iterate over time steps\n",
    "        for node_idx, node in enumerate(floating_nodes): #iterate over nodes\n",
    "            if(floating_valid_points[timestep_idx,node_idx]):\n",
    "                variable_to_node.append((node,timestep_idx)) #we store the floating nodes as node, timestep tuples\n",
    "    variable_to_node_map = {}\n",
    "    for v_idx,v in enumerate(variable_to_node):\n",
    "        variable_to_node_map[v] = v_idx\n",
    "    \n",
    "    #print len(variable_to_node)\n",
    "    \n",
    "    offset_variable_to_pair = [] #offset variables: pairs of nodes == tricky\n",
    "    for c in constraints:\n",
    "        #find out if we already have an offset variable for this constraint pair\n",
    "        if(not c[0]==\"bar\"): #bar constraints don't have offsets\n",
    "            pair = tuple(np.sort(c[1]))\n",
    "            if(not pair in offset_variable_to_pair):\n",
    "                offset_variable_to_pair.append(pair)\n",
    "    \n",
    "    num_offsets = len(offset_variable_to_pair)\n",
    "    num_variables = len(variable_to_node)\n",
    "    num_constraints = len(constraints)\n",
    "    \n",
    "    #print len(offset_variable_to_pair)\n",
    "    #TODO: constraints\n",
    "    #print len(constraints)\n",
    "    \n",
    "    #Generate the measurement vector, variable to constraint matrices and offset to constraint matrices\n",
    "    measurement_vector = np.zeros(num_constraints)\n",
    "    variables_to_CSTR_X = np.zeros((num_constraints,num_variables))\n",
    "    variables_to_CSTR_Y = np.zeros(variables_to_CSTR_X.shape)\n",
    "    offsets_to_CSTR = np.zeros((num_constraints,num_offsets))\n",
    "    #print floating_valid_points\n",
    "    for c_idx,c in enumerate(constraints):\n",
    "        measurement_vector[c_idx] = c[2]\n",
    "        #find the correct offset variable\n",
    "        if(c[0]==\"bar\"):\n",
    "            #bar constraints don't have offsets\n",
    "            offsets_to_CSTR[c_idx,:] = 0 \n",
    "        else:\n",
    "            pair = tuple(np.sort(c[1]))\n",
    "            offset_idx = offset_variable_to_pair.index(pair)\n",
    "            offsets_to_CSTR[c_idx,offset_idx] = 1 \n",
    "        #find the correct nodal coordinate variables\n",
    "        if(c[0]==\"bar\" or c[0]==\"float_to_float\"):\n",
    "            #print c\n",
    "            from_ = tuple((c[1][0],c[3])) #node,timestep\n",
    "            to_ = tuple((c[1][1],c[3]))\n",
    "            from_idx = variable_to_node_map[from_]\n",
    "            to_idx = variable_to_node_map[to_]\n",
    "            variables_to_CSTR_X[c_idx,from_idx] = 1\n",
    "            variables_to_CSTR_Y[c_idx,to_idx] = 1\n",
    "        else:\n",
    "            #float to fixed\n",
    "            if(c[1][0] in fixed_nodes):\n",
    "                from_ = c[1][0]\n",
    "                to_ = tuple((c[1][1],c[3]))\n",
    "            else:\n",
    "                from_ = tuple((c[1][0],c[3]))\n",
    "                to_ = c[1][1]\n",
    "\n",
    "            from_idx = variable_to_node_map[from_]\n",
    "            to_idx = variable_to_node_map[to_]\n",
    "            variables_to_CSTR_X[c_idx,from_idx] = 1\n",
    "            variables_to_CSTR_Y[c_idx,to_idx] = 1\n",
    "        #variables_to_CSTR_X[c_idx,variable_to_node.index(c[1][0])] = 1\n",
    "        #variables_to_CSTR_Y[c_idx,variable_to_node.index(c[1][1])] = 1\n",
    "        \n",
    "        \n",
    "    def deriv_func(N,o):\n",
    "        X = variables_to_CSTR_X.dot(N)\n",
    "        Y = variables_to_CSTR_Y.dot(N)\n",
    "        O = offsets_to_CSTR.dot(o.reshape((num_offsets,1))) \n",
    "        #print X.shape\n",
    "        #print Y.shape\n",
    "        #print O.shape\n",
    "        #print m.shape\n",
    "        dX,dY,dO = derivative_cost_function(X,Y,measurement_vector.ravel(),O.ravel())\n",
    "        dN = variables_to_CSTR_X.T.dot(dX) +  variables_to_CSTR_Y.T.dot(dY)\n",
    "        dN[0,:] = 0\n",
    "        dN[1,1:] = 0\n",
    "        dN[2,2] = 0\n",
    "        do = offsets_to_CSTR.T.dot(dO.reshape((-1,1))).ravel()\n",
    "        return dN,do\n",
    "    \n",
    "    def cost_func(N,o):\n",
    "        X = variables_to_CSTR_X.dot(N)\n",
    "        Y = variables_to_CSTR_Y.dot(N)\n",
    "        O = offsets_to_CSTR.dot(o.reshape((num_offsets,1))) \n",
    "        return cost_function(X,Y,measurement_vector.ravel(),O.ravel())\n",
    "    \n",
    "    #print offsets_to_CSTR\n",
    "    #print variables_to_CSTR_X\n",
    "    #create m vector\n",
    "    return deriv_func,cost_func, num_variables, num_offsets, variable_to_node, variable_to_node_map, offset_variable_to_pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import scipy.io as sio\n",
    "sio.savemat(\"data_outdoors_preprocessed.mat\",\n",
    "            {'fixed_nodes':fixed_nodes,'floating_nodes':floating_nodes,'dist_pairs':dist_pairs,'m':m})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(93, 48)\n",
      "7.67978883168\n",
      "(93, 48)\n",
      "59.3674071168\n",
      "(93, 48)\n",
      "9.49186303424\n",
      "(93, 48)\n",
      "16.8894457278\n",
      "(93, 48)\n",
      "53.7911434061\n",
      "(93, 48)\n",
      "10.9263155717\n",
      "(93, 48)\n",
      "11.9774879487\n",
      "(93, 48)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-e162fa62f232>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     64\u001b[0m         \u001b[0mresall\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m     \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mso\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfmin_bfgs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcost_fun\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX_initial\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfprime\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcost_grad\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdisp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mgtol\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1e-10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mprogress\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     67\u001b[0m     \u001b[0mcf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcost_fun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mres\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m     \u001b[0mresults_and_costs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mres\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvariable_to_node_map\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0moffset_variable_to_pair\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/lib/python2.7/dist-packages/scipy/optimize/optimize.pyc\u001b[0m in \u001b[0;36mfmin_bfgs\u001b[1;34m(f, x0, fprime, args, gtol, norm, epsilon, maxiter, full_output, disp, retall, callback)\u001b[0m\n\u001b[0;32m    775\u001b[0m             'return_all': retall}\n\u001b[0;32m    776\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 777\u001b[1;33m     \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_minimize_bfgs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfprime\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallback\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mopts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    778\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfull_output\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/lib/python2.7/dist-packages/scipy/optimize/optimize.pyc\u001b[0m in \u001b[0;36m_minimize_bfgs\u001b[1;34m(fun, x0, args, jac, callback, gtol, norm, eps, maxiter, disp, return_all, **unknown_options)\u001b[0m\n\u001b[0;32m    889\u001b[0m         \u001b[0mA1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mI\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0msk\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0myk\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mrhok\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    890\u001b[0m         \u001b[0mA2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mI\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0myk\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0msk\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mrhok\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 891\u001b[1;33m         Hk = numpy.dot(A1, numpy.dot(Hk, A2)) + (rhok * sk[:, numpy.newaxis] *\n\u001b[0m\u001b[0;32m    892\u001b[0m                                                  sk[numpy.newaxis, :])\n\u001b[0;32m    893\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "cf = 10\n",
    "cf_min = cf\n",
    "results_and_costs = []\n",
    "while cf>0.1:\n",
    "    fixed_nodes = np.array([16,15,14,13],dtype=int)\n",
    "    floating_nodes = np.array([1,2,5,6,7,8,9,10,11,12],dtype=int)#,2],dtype=int)\n",
    "    #dist_pairs = np.array([[2,13],[2,14],[2,15],[2,16],\n",
    "    #                       [1,13],[1,14],[1,15],[1,16],\n",
    "    #                       [4,13],[1,14],[1,15],[1,16],\n",
    "    #                       [6,13],[1,14],[1,15],[1,16],\n",
    "    #                       [8,13],[1,14],[1,15],[1,16],\n",
    "    #                       [,13],[1,14],[1,15],[1,16],\n",
    "    #                       [1,13],[1,14],[1,15],[1,16]\n",
    "    #                      ],dtype=int)\n",
    "                           #np.array([[1,10],[2,10],[4,10],[7,10],[8,10],[12,10],[13,10],[16,10]],dtype=int)\n",
    "    dist_pairs = topics_node_to_node\n",
    "    \n",
    "    #0,1,2,4,6,8,10\n",
    "\n",
    "    a = np.arange(meas[0].shape[0])\n",
    "    np.random.shuffle(a)\n",
    "    m = meas[0][a[::7],:]#[:,(0,1,2,3,4,5,6,8)]\n",
    "    print m.shape\n",
    "    #m = np.hstack((m,np.ones((m.shape[0],1))*1.36))\n",
    "    df,cf,DOF,num_offsets,variable_to_node,variable_to_node_map, offset_variable_to_pair  = \n",
    "    create_data(fixed_nodes,floating_nodes,dist_pairs,m)\n",
    "\n",
    "    N,o = np.random.randn(DOF,3)*3,np.zeros(num_offsets)+3.8\n",
    "    N[0] = 0\n",
    "    N[1,1:] = 0\n",
    "    N[2,2] = 0     \n",
    "    #B=np.array([[ 0.,          0.,          0.        ],\n",
    "    #                 [ -3.38,  0.,          0.        ],\n",
    "    #                 [ -0.7039,  -2.189,  0.        ]])\n",
    "    B = np.array([[0,0,0],\n",
    "                 [9.97,0,0],\n",
    "                 [3.15,11.16,0]])\n",
    "    #N[:3] = B\n",
    "\n",
    "    dN,do = df(N,o)\n",
    "    #print cf(N,o)\n",
    "\n",
    "    import scipy.optimize as so\n",
    "    Nf = N.ravel()\n",
    "    X_initial = np.hstack((Nf,o))\n",
    "    def cost_fun(x):\n",
    "        Nt = x[:-o.shape[0]].reshape((DOF,3))\n",
    "        #Nt[:3] = B\n",
    "        reg = 0.05*np.sum((x[-o.shape[0]:]-3.8)**2)#+0.5*(x[11]-2.5)**2#+0.05*(x[10]-2.)**2+0.05*(x[9]-2.)**2\n",
    "        return cf(Nt ,x[-o.shape[0]:])+reg\n",
    "    def cost_grad(x):\n",
    "        dN,do = df(x[:-o.shape[0]].reshape((DOF,3)),x[-o.shape[0]:])\n",
    "        #dN[:3] = 0\n",
    "        #do[:] = 0\n",
    "        do += 0.05*2*(x[-o.shape[0]:]-3.8)\n",
    "        dN = dN.ravel()\n",
    "        #dN[11] += 0.5*2*(x[11]-2.5)\n",
    "        #dN[10] += 0.05*2*(x[10]-2.)\n",
    "        #dN[9] += 0.05*2*(x[9]-2.)\n",
    "        return np.hstack((dN,do))\n",
    "\n",
    "\n",
    "    resall = []\n",
    "    def progress(x):\n",
    "        resall.append(x)\n",
    "\n",
    "    res = so.fmin_bfgs(cost_fun,X_initial,fprime=cost_grad,disp=0,gtol=1e-10,callback=progress)\n",
    "    cf = cost_fun(res)\n",
    "    results_and_costs.append((res.copy(),cf,variable_to_node_map,offset_variable_to_pair,a.copy()))\n",
    "    if(cf<cf_min):\n",
    "        res_min = res.copy()\n",
    "        DOF_min = DOF\n",
    "        variable_to_node_map_min =  variable_to_node_map\n",
    "        offset_variable_to_pair_min = offset_variable_to_pair\n",
    "        cf_min = cf\n",
    "    print cf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    }
   ],
   "source": [
    "\n",
    "%prun so.fmin_bfgs(cost_fun,X_initial,fprime=cost_grad,disp=0,gtol=1e-10,callback=progress)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#cost_fun(res_min)\n",
    "res=res_min.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 4.06  3.76  4.03  3.81  3.62  3.76  3.59  4.22  4.    3.75  4.06  3.71\n",
      "  4.11  3.68  4.06  3.8   3.91  3.87  3.92  3.85  4.04  3.68  4.02  3.75\n",
      "  4.12  3.82  3.84  3.68  3.88  3.69  4.22  3.91  4.16  3.88  4.17  3.91\n",
      "  4.37  3.58  4.04  3.75]\n"
     ]
    }
   ],
   "source": [
    "print res[-o.shape[0]:].round(2)\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "p = res[:fixed_nodes.shape[0]*3].reshape((fixed_nodes.shape[0],3))[:fixed_nodes.shape[0]]\n",
    "#p[0,1]+=1\n",
    "p2 = res[:-len(offset_variable_to_pair)].reshape(((res.shape[0]-len(offset_variable_to_pair))/3,3))[fixed_nodes.shape[0]:]\n",
    "ax.scatter(p[:,0],p[:,1],p[:,2],c='b')\n",
    "for i in xrange(fixed_nodes.shape[0]):\n",
    "    ax.text(p[i,0],p[i,1],p[i,2],fixed_nodes[i])\n",
    "\n",
    "ax.scatter(p2[:,0],p2[:,1],p2[:,2],c='y')\n",
    "#ax.scatter(pc[:,0],pc[:,1],pc[:,2],c='b')\n",
    "#ax.scatter(p2c[:,0],p2c[:,1],p2c[:,2],c='r')\n",
    "ax.set_aspect('equal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0.           0.           0.        ]\n",
      " [-10.37797144   0.           0.        ]\n",
      " [ -3.26848811  11.53203134   0.        ]\n",
      " [ -7.15833895   4.28769715   0.78079217]]\n",
      "[[  0.     0.     0.  ]\n",
      " [  9.97   0.     0.  ]\n",
      " [  3.15  11.16   0.  ]]\n"
     ]
    }
   ],
   "source": [
    "p_all = res[:12].reshape((4,3))\n",
    "print p_all\n",
    "print B\n",
    "#np.linalg.norm(p_all[20]-p_all[21])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3.82447262,  3.87178301,  3.65002531,  3.96786277,  4.00467714,\n",
       "        3.81267492,  4.00032556,  3.86155599,  3.67771007,  3.97125125])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3.94104845,  3.91390719,  3.98168363,  3.95158926,  3.91548744,\n",
       "        3.92860805,  4.06065676,  3.97498433,  3.81817403,  3.94787904,\n",
       "        4.00990517,  3.81977139,  3.84350277,  3.84733697,  4.04858242,\n",
       "        3.94446129,  3.44145357,  4.31821431,  3.72509005,  3.99935807,\n",
       "        3.89396468,  3.92934977,  4.03061451,  3.96842817,  3.79052255,\n",
       "        3.94863262,  4.28768486,  4.05678094,  3.98560302,  3.86303144,\n",
       "        3.93073998,  3.8429706 ,  4.4024697 ,  3.27055469,  3.95555874,\n",
       "        3.75330747,  3.8570016 ,  3.74400632,  3.72075997,  4.2030231 ])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[-o.shape[0]:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2, 13),\n",
       " (2, 14),\n",
       " (2, 15),\n",
       " (2, 16),\n",
       " (1, 13),\n",
       " (1, 14),\n",
       " (1, 15),\n",
       " (1, 16),\n",
       " (4, 13),\n",
       " (4, 14),\n",
       " (4, 15),\n",
       " (4, 16),\n",
       " (6, 13),\n",
       " (6, 14),\n",
       " (6, 15),\n",
       " (6, 16),\n",
       " (10, 13),\n",
       " (10, 14),\n",
       " (10, 15),\n",
       " (10, 16),\n",
       " (8, 13),\n",
       " (8, 14),\n",
       " (8, 15),\n",
       " (8, 16),\n",
       " (12, 13),\n",
       " (12, 14),\n",
       " (12, 15),\n",
       " (12, 16)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "offset_variable_to_pair_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4.16799159,  3.63648985,  4.03304079,  3.83795675,  4.02615586,\n",
       "        3.68629254,  4.03762013,  3.89848137,  4.18677463,  3.62661513,\n",
       "        4.02919902,  3.79128936,  3.24252253,  3.74993813,  3.54417684,\n",
       "        3.63720535,  4.21208742,  3.54548237,  4.18295844,  3.71217001,\n",
       "        4.06504594,  3.65841194,  4.2756098 ,  3.93173312,  3.3867485 ,\n",
       "        3.76147812,  3.18438827,  3.92609695])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[-len(offset_variable_to_pair_min):]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import scipy.io as sio\n",
    "sio.savemat(\"offsets_outdoors_nobasepoints_given_longrun.mat\",{\"offset_variable_to_pair\":np.array(offset_variable_to_pair_min),'offsets':res_min[-len(offset_variable_to_pair_min):]})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
